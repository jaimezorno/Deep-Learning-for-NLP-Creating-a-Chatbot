{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for NLP - Creating a chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Library Imports\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve training data\n",
    "with open('train_qa.txt', 'rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve test data\n",
    "with open('test_qa.txt', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of training instances\n",
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of test instances\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Sandra',\n",
       "  'went',\n",
       "  'back',\n",
       "  'to',\n",
       "  'the',\n",
       "  'hallway',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'office',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'office', '?'],\n",
       " 'yes')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of one of the instances\n",
    "train_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sandra went back to the hallway . Sandra moved to the office .'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[10][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the office ?'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[10][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we need to create a vocabulary with our data\n",
    "#For this we will use the training data only to - On the video it uses both\n",
    "#train and test \n",
    "#Might have to use training and test later, as the dataset has very\n",
    "#few words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we will build a set of all the words in the dataset:\n",
    "vocab = set()\n",
    "for story, question, answer in train_data:\n",
    "    vocab = vocab.union(set(story)) #Set returns unique words in the sentence\n",
    "                                    #Union returns the unique common elements from a two sets\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate len and add 1 for Keras placeholder - Placeholders are used to feed in the data to the network. \n",
    "#They need a data type, and have optional shape arguements.\n",
    "#They will be empty at first, and then the data will get fed into the placeholder\n",
    "vocab_len = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we are going to calculate the longest story and the longest question\n",
    "#We need this for the Keras pad sequences. \n",
    "#Keras training layers expect all of the input to have the same length, so \n",
    "#we need to pad \n",
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_story_lens = [len(data[0]) for data in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = (max(all_story_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will go through a manual process of how to vectorize the data, and then we will create a function that does this automatically for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaime\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an instance of the tokenizer object:\n",
    "tokenizer = Tokenizer(filters = [])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grabbed': 1,\n",
       " 'got': 2,\n",
       " 'bedroom': 3,\n",
       " 'dropped': 4,\n",
       " 'back': 5,\n",
       " 'put': 6,\n",
       " 'mary': 7,\n",
       " 'garden': 8,\n",
       " 'hallway': 9,\n",
       " 'sandra': 10,\n",
       " 'took': 11,\n",
       " 'in': 12,\n",
       " 'down': 13,\n",
       " 'office': 14,\n",
       " 'up': 15,\n",
       " 'went': 16,\n",
       " 'to': 17,\n",
       " 'discarded': 18,\n",
       " 'journeyed': 19,\n",
       " 'is': 20,\n",
       " 'picked': 21,\n",
       " 'there': 22,\n",
       " 'left': 23,\n",
       " 'bathroom': 24,\n",
       " 'travelled': 25,\n",
       " 'apple': 26,\n",
       " 'yes': 27,\n",
       " 'moved': 28,\n",
       " '?': 29,\n",
       " 'no': 30,\n",
       " 'daniel': 31,\n",
       " 'kitchen': 32,\n",
       " 'john': 33,\n",
       " 'football': 34,\n",
       " 'the': 35,\n",
       " '.': 36,\n",
       " 'milk': 37}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dictionary that maps every word in our vocab to an index\n",
    "# It has been automatically lowercased\n",
    "#This tokenizer can give different indexes for different words depending on when we run it\n",
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the stories, questions and answers:\n",
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating each of the elements\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question) \n",
    "    train_answers.append(answer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coverting the text into the indexes \n",
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function for vectorizing the stories, questions and answers:\n",
    "def vectorize_stories(data,word_index = tokenizer.word_index, max_story_len = max_story_len, max_question_len = max_question_len):\n",
    "    #vectorized stories:\n",
    "    X = []\n",
    "    #vectorized questions:\n",
    "    Xq = []\n",
    "    #vectorized answers:\n",
    "    Y = []\n",
    "    \n",
    "    for story, question, answer in data:\n",
    "        #Getting indexes for each word in the story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        #Getting indexes for each word in the story\n",
    "        xq = [word_index[word.lower()] for word in question]\n",
    "        #For the answers\n",
    "        y = np.zeros(len(word_index) + 1) #Index 0 Reserved when padding the sequences\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    #Now we have to pad these sequences:\n",
    "    return(pad_sequences(X,maxlen=max_story_len), pad_sequences(Xq, maxlen=max_question_len), np.array(Y))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, questions_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, questions_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  7, 28, 17, 35, 24, 36, 10, 19, 17,\n",
       "       35,  3, 36])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bathroom',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'journeyed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_story_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 28, 17, 35, 24, 36, 10, 19, 17, 35, 3, 36]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_story_seq[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, dot, concatenate, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create the placeholders \n",
    "#The Input function is used to create a keras tensor\n",
    "#PLACEHOLDER shape = (max_story_len,batch_size)\n",
    "#These are our placeholder for the inputs, ready to recieve batches of the stories and the questions\n",
    "input_sequence = Input((max_story_len,)) #As we dont know batch size yet\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create input encoder M:\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_len,output_dim = 64)) #From paper\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "#Outputs: (Samples, story_maxlen,embedding_dim) -- Gives a list of the lenght of the samples where each item has the\n",
    "#lenght of the max story lenght and every word is embedded in the embbeding dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create input encoder C:\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_len,output_dim = max_question_len)) #From paper\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "\n",
    "#Outputs: (samples, story_maxlen, max_question_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create question encoder:\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_len,output_dim = 64,input_length=max_question_len)) #From paper\n",
    "question_encoder.add(Dropout(0.3))\n",
    "\n",
    "#Outputs: (samples, question_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets encode the sequences, passing the placeholders into our encoders:\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use dot product to compute similarity between input encoded m and question \n",
    "#Like in the paper:\n",
    "match = dot([input_encoded_m,question_encoded], axes = (2,2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the response we want to add this match with the ouput of input_encoded_c\n",
    "response = add([match,input_encoded_c])\n",
    "response = Permute((2,1))(response) #Permute Layer: permutes dimensions of input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once we have the response we can concatenate it with the question encoded:\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the answer tensor with a RNN (LSTM)\n",
    "answer = LSTM(32)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regularization with dropout:\n",
    "answer = Dropout(0.5)(answer)\n",
    "#Output layer:\n",
    "answer = Dense(vocab_len)(answer) #Output shape: (Samples, Vocab_size) #Yes or no and all 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to output a probability distribution for the vocab, using softmax:\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we build the final model:\n",
    "model = Model([input_sequence,question], answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "#Categorical instead of binary cross entropy as because of the way we are training\n",
    "#we could actually see any of the words from the vocab as output\n",
    "#however, we should only see yes or no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_1[1][0]               \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_2[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/1000\n",
      "10000/10000 [==============================] - 3s 294us/step - loss: 0.6712 - acc: 0.5812 - val_loss: 0.6591 - val_acc: 0.6410\n",
      "Epoch 2/1000\n",
      "10000/10000 [==============================] - 3s 298us/step - loss: 0.6466 - acc: 0.6206 - val_loss: 0.6240 - val_acc: 0.6680\n",
      "Epoch 3/1000\n",
      "10000/10000 [==============================] - 3s 295us/step - loss: 0.6258 - acc: 0.6455 - val_loss: 0.6041 - val_acc: 0.6680\n",
      "Epoch 4/1000\n",
      "10000/10000 [==============================] - 3s 300us/step - loss: 0.6108 - acc: 0.6665 - val_loss: 0.5749 - val_acc: 0.6930\n",
      "Epoch 5/1000\n",
      "10000/10000 [==============================] - 4s 426us/step - loss: 0.5781 - acc: 0.7000 - val_loss: 0.5370 - val_acc: 0.7290\n",
      "Epoch 6/1000\n",
      "10000/10000 [==============================] - 4s 416us/step - loss: 0.5525 - acc: 0.7190 - val_loss: 0.5079 - val_acc: 0.7480\n",
      "Epoch 7/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.5284 - acc: 0.7427 - val_loss: 0.4763 - val_acc: 0.7850\n",
      "Epoch 8/1000\n",
      "10000/10000 [==============================] - 4s 403us/step - loss: 0.4889 - acc: 0.7805 - val_loss: 0.5258 - val_acc: 0.7690\n",
      "Epoch 9/1000\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.4546 - acc: 0.8017 - val_loss: 0.4215 - val_acc: 0.8210\n",
      "Epoch 10/1000\n",
      "10000/10000 [==============================] - 4s 413us/step - loss: 0.4303 - acc: 0.8179 - val_loss: 0.4409 - val_acc: 0.7970\n",
      "Epoch 11/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.4090 - acc: 0.8251 - val_loss: 0.3985 - val_acc: 0.8270\n",
      "Epoch 12/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.3958 - acc: 0.8329 - val_loss: 0.4027 - val_acc: 0.8080\n",
      "Epoch 13/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.3866 - acc: 0.8365 - val_loss: 0.4101 - val_acc: 0.8140\n",
      "Epoch 14/1000\n",
      "10000/10000 [==============================] - 4s 418us/step - loss: 0.3700 - acc: 0.8459 - val_loss: 0.3917 - val_acc: 0.8220\n",
      "Epoch 15/1000\n",
      "10000/10000 [==============================] - 4s 407us/step - loss: 0.3652 - acc: 0.8467 - val_loss: 0.3718 - val_acc: 0.8270\n",
      "Epoch 16/1000\n",
      "10000/10000 [==============================] - 4s 407us/step - loss: 0.3602 - acc: 0.8456 - val_loss: 0.3715 - val_acc: 0.8230\n",
      "Epoch 17/1000\n",
      "10000/10000 [==============================] - 4s 407us/step - loss: 0.3525 - acc: 0.8523 - val_loss: 0.3942 - val_acc: 0.8220\n",
      "Epoch 18/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.3491 - acc: 0.8548 - val_loss: 0.3535 - val_acc: 0.8320\n",
      "Epoch 19/1000\n",
      "10000/10000 [==============================] - 4s 409us/step - loss: 0.3424 - acc: 0.8529 - val_loss: 0.3863 - val_acc: 0.8130\n",
      "Epoch 20/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.3417 - acc: 0.8596 - val_loss: 0.3786 - val_acc: 0.8220\n",
      "Epoch 21/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.3326 - acc: 0.8589 - val_loss: 0.3893 - val_acc: 0.8210\n",
      "Epoch 22/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.3331 - acc: 0.8555 - val_loss: 0.3574 - val_acc: 0.8260\n",
      "Epoch 23/1000\n",
      "10000/10000 [==============================] - 4s 408us/step - loss: 0.3309 - acc: 0.8562 - val_loss: 0.3974 - val_acc: 0.8210\n",
      "Epoch 24/1000\n",
      "10000/10000 [==============================] - 4s 414us/step - loss: 0.3335 - acc: 0.8578 - val_loss: 0.3533 - val_acc: 0.8340\n",
      "Epoch 25/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.3287 - acc: 0.8596 - val_loss: 0.3828 - val_acc: 0.8160\n",
      "Epoch 26/1000\n",
      "10000/10000 [==============================] - 4s 427us/step - loss: 0.3261 - acc: 0.8625 - val_loss: 0.3715 - val_acc: 0.8210\n",
      "Epoch 27/1000\n",
      "10000/10000 [==============================] - 4s 411us/step - loss: 0.3202 - acc: 0.8599 - val_loss: 0.3566 - val_acc: 0.8250\n",
      "Epoch 28/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.3190 - acc: 0.8600 - val_loss: 0.3712 - val_acc: 0.8280\n",
      "Epoch 29/1000\n",
      "10000/10000 [==============================] - 4s 413us/step - loss: 0.3214 - acc: 0.8605 - val_loss: 0.3614 - val_acc: 0.8240\n",
      "Epoch 30/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.3181 - acc: 0.8622 - val_loss: 0.3641 - val_acc: 0.8330\n",
      "Epoch 31/1000\n",
      "10000/10000 [==============================] - 4s 419us/step - loss: 0.3114 - acc: 0.8645 - val_loss: 0.3598 - val_acc: 0.8310\n",
      "Epoch 32/1000\n",
      "10000/10000 [==============================] - 4s 414us/step - loss: 0.3145 - acc: 0.8637 - val_loss: 0.3549 - val_acc: 0.8320\n",
      "Epoch 33/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.3162 - acc: 0.8599 - val_loss: 0.3522 - val_acc: 0.8260\n",
      "Epoch 34/1000\n",
      "10000/10000 [==============================] - 4s 419us/step - loss: 0.3111 - acc: 0.8607 - val_loss: 0.3705 - val_acc: 0.8280\n",
      "Epoch 35/1000\n",
      "10000/10000 [==============================] - 4s 432us/step - loss: 0.3091 - acc: 0.8689 - val_loss: 0.3385 - val_acc: 0.8340\n",
      "Epoch 36/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.3107 - acc: 0.8621 - val_loss: 0.3421 - val_acc: 0.8350\n",
      "Epoch 37/1000\n",
      "10000/10000 [==============================] - 4s 423us/step - loss: 0.3087 - acc: 0.8671 - val_loss: 0.3683 - val_acc: 0.8260\n",
      "Epoch 38/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.3053 - acc: 0.8660 - val_loss: 0.3435 - val_acc: 0.8300\n",
      "Epoch 39/1000\n",
      "10000/10000 [==============================] - 4s 414us/step - loss: 0.3046 - acc: 0.8668 - val_loss: 0.3643 - val_acc: 0.8290\n",
      "Epoch 40/1000\n",
      "10000/10000 [==============================] - 4s 413us/step - loss: 0.3092 - acc: 0.8659 - val_loss: 0.3495 - val_acc: 0.8370\n",
      "Epoch 41/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.3023 - acc: 0.8652 - val_loss: 0.3578 - val_acc: 0.8300\n",
      "Epoch 42/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.3034 - acc: 0.8703 - val_loss: 0.3588 - val_acc: 0.8390\n",
      "Epoch 43/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.2985 - acc: 0.8672 - val_loss: 0.3501 - val_acc: 0.8380\n",
      "Epoch 44/1000\n",
      "10000/10000 [==============================] - 4s 413us/step - loss: 0.3040 - acc: 0.8694 - val_loss: 0.3485 - val_acc: 0.8320\n",
      "Epoch 45/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.2996 - acc: 0.8692 - val_loss: 0.3748 - val_acc: 0.8320\n",
      "Epoch 46/1000\n",
      "10000/10000 [==============================] - 4s 416us/step - loss: 0.3016 - acc: 0.8694 - val_loss: 0.3649 - val_acc: 0.8280\n",
      "Epoch 47/1000\n",
      "10000/10000 [==============================] - 4s 414us/step - loss: 0.3011 - acc: 0.8674 - val_loss: 0.3513 - val_acc: 0.8340\n",
      "Epoch 48/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.2969 - acc: 0.8672 - val_loss: 0.3780 - val_acc: 0.8310\n",
      "Epoch 49/1000\n",
      "10000/10000 [==============================] - 4s 424us/step - loss: 0.2992 - acc: 0.8704 - val_loss: 0.3518 - val_acc: 0.8220\n",
      "Epoch 50/1000\n",
      "10000/10000 [==============================] - 4s 418us/step - loss: 0.2948 - acc: 0.8723 - val_loss: 0.3643 - val_acc: 0.8410\n",
      "Epoch 51/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.2936 - acc: 0.8723 - val_loss: 0.3586 - val_acc: 0.8280\n",
      "Epoch 52/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.2950 - acc: 0.8742 - val_loss: 0.3585 - val_acc: 0.8240\n",
      "Epoch 53/1000\n",
      "10000/10000 [==============================] - 4s 418us/step - loss: 0.2991 - acc: 0.8703 - val_loss: 0.3499 - val_acc: 0.8210\n",
      "Epoch 54/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.2920 - acc: 0.8710 - val_loss: 0.3608 - val_acc: 0.8310\n",
      "Epoch 55/1000\n",
      "10000/10000 [==============================] - 4s 418us/step - loss: 0.2904 - acc: 0.8732 - val_loss: 0.3548 - val_acc: 0.8310\n",
      "Epoch 56/1000\n",
      "10000/10000 [==============================] - 4s 419us/step - loss: 0.2889 - acc: 0.8764 - val_loss: 0.3557 - val_acc: 0.8270\n",
      "Epoch 57/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.2920 - acc: 0.8708 - val_loss: 0.3588 - val_acc: 0.8370\n",
      "Epoch 58/1000\n",
      "10000/10000 [==============================] - 4s 419us/step - loss: 0.2907 - acc: 0.8750 - val_loss: 0.3814 - val_acc: 0.8260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "10000/10000 [==============================] - 4s 395us/step - loss: 0.2892 - acc: 0.8735 - val_loss: 0.3543 - val_acc: 0.8330\n",
      "Epoch 60/1000\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.2868 - acc: 0.8753 - val_loss: 0.3536 - val_acc: 0.8360\n",
      "Epoch 61/1000\n",
      "10000/10000 [==============================] - 4s 409us/step - loss: 0.2882 - acc: 0.8759 - val_loss: 0.3549 - val_acc: 0.8300\n",
      "Epoch 62/1000\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.2848 - acc: 0.8793 - val_loss: 0.3564 - val_acc: 0.8330\n",
      "Epoch 63/1000\n",
      "10000/10000 [==============================] - 4s 393us/step - loss: 0.2875 - acc: 0.8761 - val_loss: 0.3732 - val_acc: 0.8310\n",
      "Epoch 64/1000\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.2857 - acc: 0.8753 - val_loss: 0.3737 - val_acc: 0.8290\n",
      "Epoch 65/1000\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.2791 - acc: 0.8798 - val_loss: 0.3685 - val_acc: 0.8250\n",
      "Epoch 66/1000\n",
      "10000/10000 [==============================] - 4s 397us/step - loss: 0.2792 - acc: 0.8801 - val_loss: 0.3624 - val_acc: 0.8280\n",
      "Epoch 67/1000\n",
      "10000/10000 [==============================] - 4s 418us/step - loss: 0.2841 - acc: 0.8762 - val_loss: 0.3702 - val_acc: 0.8280\n",
      "Epoch 68/1000\n",
      "10000/10000 [==============================] - 4s 408us/step - loss: 0.2822 - acc: 0.8763 - val_loss: 0.3626 - val_acc: 0.8240\n",
      "Epoch 69/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.2808 - acc: 0.8771 - val_loss: 0.3638 - val_acc: 0.8310\n",
      "Epoch 70/1000\n",
      "10000/10000 [==============================] - 4s 408us/step - loss: 0.2783 - acc: 0.8803 - val_loss: 0.3589 - val_acc: 0.8270\n",
      "Epoch 71/1000\n",
      "10000/10000 [==============================] - 4s 405us/step - loss: 0.2798 - acc: 0.8817 - val_loss: 0.3771 - val_acc: 0.8270\n",
      "Epoch 72/1000\n",
      "10000/10000 [==============================] - 4s 413us/step - loss: 0.2810 - acc: 0.8776 - val_loss: 0.3558 - val_acc: 0.8330\n",
      "Epoch 73/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.2778 - acc: 0.8817 - val_loss: 0.4093 - val_acc: 0.8210\n",
      "Epoch 74/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.2809 - acc: 0.8804 - val_loss: 0.3839 - val_acc: 0.8290\n",
      "Epoch 75/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.2802 - acc: 0.8822 - val_loss: 0.3636 - val_acc: 0.8310\n",
      "Epoch 76/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.2789 - acc: 0.8766 - val_loss: 0.3863 - val_acc: 0.8320\n",
      "Epoch 77/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.2753 - acc: 0.8815 - val_loss: 0.3928 - val_acc: 0.8390\n",
      "Epoch 78/1000\n",
      "10000/10000 [==============================] - 4s 419us/step - loss: 0.2751 - acc: 0.8830 - val_loss: 0.3849 - val_acc: 0.8330\n",
      "Epoch 79/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.2721 - acc: 0.8833 - val_loss: 0.3980 - val_acc: 0.8340\n",
      "Epoch 80/1000\n",
      "10000/10000 [==============================] - 4s 416us/step - loss: 0.2757 - acc: 0.8819 - val_loss: 0.3743 - val_acc: 0.8300\n",
      "Epoch 81/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.2712 - acc: 0.8825 - val_loss: 0.4315 - val_acc: 0.8330\n",
      "Epoch 82/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.2678 - acc: 0.8892 - val_loss: 0.4050 - val_acc: 0.8270\n",
      "Epoch 83/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.2677 - acc: 0.8836 - val_loss: 0.3853 - val_acc: 0.8270\n",
      "Epoch 84/1000\n",
      "10000/10000 [==============================] - 4s 414us/step - loss: 0.2634 - acc: 0.8856 - val_loss: 0.3985 - val_acc: 0.8190\n",
      "Epoch 85/1000\n",
      "10000/10000 [==============================] - 4s 421us/step - loss: 0.2657 - acc: 0.8849 - val_loss: 0.4018 - val_acc: 0.8280\n",
      "Epoch 86/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.2671 - acc: 0.8866 - val_loss: 0.3812 - val_acc: 0.8250\n",
      "Epoch 87/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.2620 - acc: 0.8871 - val_loss: 0.3873 - val_acc: 0.8340\n",
      "Epoch 88/1000\n",
      "10000/10000 [==============================] - 4s 413us/step - loss: 0.2632 - acc: 0.8886 - val_loss: 0.3992 - val_acc: 0.8300\n",
      "Epoch 89/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.2642 - acc: 0.8870 - val_loss: 0.4129 - val_acc: 0.8190\n",
      "Epoch 90/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.2561 - acc: 0.8904 - val_loss: 0.4188 - val_acc: 0.8200\n",
      "Epoch 91/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.2546 - acc: 0.8916 - val_loss: 0.3804 - val_acc: 0.8280\n",
      "Epoch 92/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.2576 - acc: 0.8910 - val_loss: 0.4081 - val_acc: 0.8220\n",
      "Epoch 93/1000\n",
      "10000/10000 [==============================] - 4s 413us/step - loss: 0.2577 - acc: 0.8913 - val_loss: 0.3907 - val_acc: 0.8250\n",
      "Epoch 94/1000\n",
      "10000/10000 [==============================] - 4s 419us/step - loss: 0.2570 - acc: 0.8892 - val_loss: 0.3967 - val_acc: 0.8200\n",
      "Epoch 95/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.2555 - acc: 0.8921 - val_loss: 0.4190 - val_acc: 0.8200\n",
      "Epoch 96/1000\n",
      "10000/10000 [==============================] - 4s 413us/step - loss: 0.2570 - acc: 0.8931 - val_loss: 0.4068 - val_acc: 0.8290\n",
      "Epoch 97/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.2607 - acc: 0.8930 - val_loss: 0.3936 - val_acc: 0.8290\n",
      "Epoch 98/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.2564 - acc: 0.8946 - val_loss: 0.4161 - val_acc: 0.8240\n",
      "Epoch 99/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.2526 - acc: 0.8931 - val_loss: 0.4228 - val_acc: 0.8330\n",
      "Epoch 100/1000\n",
      "10000/10000 [==============================] - 4s 423us/step - loss: 0.2590 - acc: 0.8921 - val_loss: 0.3916 - val_acc: 0.8180\n",
      "Epoch 101/1000\n",
      "10000/10000 [==============================] - 4s 435us/step - loss: 0.2547 - acc: 0.8898 - val_loss: 0.3955 - val_acc: 0.8230\n",
      "Epoch 102/1000\n",
      "10000/10000 [==============================] - 4s 424us/step - loss: 0.2481 - acc: 0.8948 - val_loss: 0.3968 - val_acc: 0.8320\n",
      "Epoch 103/1000\n",
      "10000/10000 [==============================] - 4s 421us/step - loss: 0.2586 - acc: 0.8903 - val_loss: 0.4249 - val_acc: 0.8260\n",
      "Epoch 104/1000\n",
      "10000/10000 [==============================] - 4s 421us/step - loss: 0.2487 - acc: 0.8950 - val_loss: 0.4347 - val_acc: 0.8280\n",
      "Epoch 105/1000\n",
      "10000/10000 [==============================] - 4s 431us/step - loss: 0.2428 - acc: 0.8998 - val_loss: 0.4187 - val_acc: 0.8350\n",
      "Epoch 106/1000\n",
      "10000/10000 [==============================] - 4s 421us/step - loss: 0.2491 - acc: 0.8971 - val_loss: 0.4413 - val_acc: 0.8270\n",
      "Epoch 107/1000\n",
      "10000/10000 [==============================] - 4s 423us/step - loss: 0.2412 - acc: 0.8976 - val_loss: 0.4265 - val_acc: 0.8190\n",
      "Epoch 108/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.2478 - acc: 0.8976 - val_loss: 0.4157 - val_acc: 0.8270\n",
      "Epoch 109/1000\n",
      "10000/10000 [==============================] - 4s 440us/step - loss: 0.2461 - acc: 0.8984 - val_loss: 0.4169 - val_acc: 0.8210\n",
      "Epoch 110/1000\n",
      "10000/10000 [==============================] - 4s 433us/step - loss: 0.2432 - acc: 0.8997 - val_loss: 0.4051 - val_acc: 0.8240\n",
      "Epoch 111/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.2369 - acc: 0.8988 - val_loss: 0.4539 - val_acc: 0.8260\n",
      "Epoch 112/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.2483 - acc: 0.8951 - val_loss: 0.4144 - val_acc: 0.8250\n",
      "Epoch 113/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.2399 - acc: 0.8980 - val_loss: 0.4665 - val_acc: 0.8190\n",
      "Epoch 114/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.2415 - acc: 0.8985 - val_loss: 0.4385 - val_acc: 0.8260\n",
      "Epoch 115/1000\n",
      "10000/10000 [==============================] - 4s 424us/step - loss: 0.2352 - acc: 0.8999 - val_loss: 0.4407 - val_acc: 0.8310\n",
      "Epoch 116/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.2333 - acc: 0.9008 - val_loss: 0.4430 - val_acc: 0.8160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/1000\n",
      "10000/10000 [==============================] - 4s 392us/step - loss: 0.2414 - acc: 0.8972 - val_loss: 0.4189 - val_acc: 0.8210\n",
      "Epoch 118/1000\n",
      "10000/10000 [==============================] - 4s 395us/step - loss: 0.2358 - acc: 0.9029 - val_loss: 0.4508 - val_acc: 0.8280\n",
      "Epoch 119/1000\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.2385 - acc: 0.9033 - val_loss: 0.4806 - val_acc: 0.8190\n",
      "Epoch 120/1000\n",
      "10000/10000 [==============================] - 4s 390us/step - loss: 0.2405 - acc: 0.9034 - val_loss: 0.4501 - val_acc: 0.8200\n",
      "Epoch 121/1000\n",
      "10000/10000 [==============================] - 4s 395us/step - loss: 0.2313 - acc: 0.9086 - val_loss: 0.4638 - val_acc: 0.8310\n",
      "Epoch 122/1000\n",
      "10000/10000 [==============================] - 4s 395us/step - loss: 0.2291 - acc: 0.9010 - val_loss: 0.4599 - val_acc: 0.8170\n",
      "Epoch 123/1000\n",
      "10000/10000 [==============================] - 4s 394us/step - loss: 0.2340 - acc: 0.9046 - val_loss: 0.4407 - val_acc: 0.8180\n",
      "Epoch 124/1000\n",
      "10000/10000 [==============================] - 4s 402us/step - loss: 0.2329 - acc: 0.9044 - val_loss: 0.4380 - val_acc: 0.8310\n",
      "Epoch 125/1000\n",
      "10000/10000 [==============================] - 4s 395us/step - loss: 0.2308 - acc: 0.9017 - val_loss: 0.4194 - val_acc: 0.8210\n",
      "Epoch 126/1000\n",
      "10000/10000 [==============================] - 4s 416us/step - loss: 0.2350 - acc: 0.9005 - val_loss: 0.4315 - val_acc: 0.8300\n",
      "Epoch 127/1000\n",
      "10000/10000 [==============================] - 4s 438us/step - loss: 0.2295 - acc: 0.9072 - val_loss: 0.4909 - val_acc: 0.8190\n",
      "Epoch 128/1000\n",
      "10000/10000 [==============================] - 5s 523us/step - loss: 0.2255 - acc: 0.9063 - val_loss: 0.5040 - val_acc: 0.8280\n",
      "Epoch 129/1000\n",
      "10000/10000 [==============================] - 5s 524us/step - loss: 0.2311 - acc: 0.9053 - val_loss: 0.4679 - val_acc: 0.8160\n",
      "Epoch 130/1000\n",
      "10000/10000 [==============================] - 4s 440us/step - loss: 0.2333 - acc: 0.9048 - val_loss: 0.4695 - val_acc: 0.8290\n",
      "Epoch 131/1000\n",
      "10000/10000 [==============================] - 4s 449us/step - loss: 0.2228 - acc: 0.9078 - val_loss: 0.4962 - val_acc: 0.8210\n",
      "Epoch 132/1000\n",
      "10000/10000 [==============================] - 4s 407us/step - loss: 0.2245 - acc: 0.9092 - val_loss: 0.4414 - val_acc: 0.8160\n",
      "Epoch 133/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.2240 - acc: 0.9043 - val_loss: 0.4687 - val_acc: 0.8240\n",
      "Epoch 134/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.2217 - acc: 0.9113 - val_loss: 0.4842 - val_acc: 0.8240\n",
      "Epoch 135/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.2292 - acc: 0.9089 - val_loss: 0.4649 - val_acc: 0.8180\n",
      "Epoch 136/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.2148 - acc: 0.9104 - val_loss: 0.4771 - val_acc: 0.8170\n",
      "Epoch 137/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.2207 - acc: 0.9086 - val_loss: 0.4718 - val_acc: 0.8210\n",
      "Epoch 138/1000\n",
      "10000/10000 [==============================] - 4s 409us/step - loss: 0.2266 - acc: 0.9074 - val_loss: 0.4425 - val_acc: 0.8220\n",
      "Epoch 139/1000\n",
      "10000/10000 [==============================] - 4s 413us/step - loss: 0.2217 - acc: 0.9081 - val_loss: 0.4478 - val_acc: 0.8200\n",
      "Epoch 140/1000\n",
      "10000/10000 [==============================] - 4s 440us/step - loss: 0.2131 - acc: 0.9141 - val_loss: 0.5215 - val_acc: 0.8220\n",
      "Epoch 141/1000\n",
      "10000/10000 [==============================] - 4s 432us/step - loss: 0.2196 - acc: 0.9105 - val_loss: 0.4824 - val_acc: 0.8200\n",
      "Epoch 142/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.2114 - acc: 0.9121 - val_loss: 0.4621 - val_acc: 0.8250\n",
      "Epoch 143/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.2130 - acc: 0.9126 - val_loss: 0.4994 - val_acc: 0.8180\n",
      "Epoch 144/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.2139 - acc: 0.9152 - val_loss: 0.4865 - val_acc: 0.8150\n",
      "Epoch 145/1000\n",
      "10000/10000 [==============================] - 4s 423us/step - loss: 0.2127 - acc: 0.9150 - val_loss: 0.4780 - val_acc: 0.8250\n",
      "Epoch 146/1000\n",
      "10000/10000 [==============================] - 4s 419us/step - loss: 0.2180 - acc: 0.9123 - val_loss: 0.5081 - val_acc: 0.8190\n",
      "Epoch 147/1000\n",
      "10000/10000 [==============================] - 4s 424us/step - loss: 0.2093 - acc: 0.9107 - val_loss: 0.4819 - val_acc: 0.8200\n",
      "Epoch 148/1000\n",
      "10000/10000 [==============================] - 4s 419us/step - loss: 0.2179 - acc: 0.9136 - val_loss: 0.4959 - val_acc: 0.8270\n",
      "Epoch 149/1000\n",
      "10000/10000 [==============================] - 4s 418us/step - loss: 0.2123 - acc: 0.9143 - val_loss: 0.4872 - val_acc: 0.8120\n",
      "Epoch 150/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.2135 - acc: 0.9132 - val_loss: 0.5120 - val_acc: 0.8170\n",
      "Epoch 151/1000\n",
      "10000/10000 [==============================] - 4s 419us/step - loss: 0.2071 - acc: 0.9168 - val_loss: 0.4889 - val_acc: 0.8290\n",
      "Epoch 152/1000\n",
      "10000/10000 [==============================] - 4s 432us/step - loss: 0.2128 - acc: 0.9152 - val_loss: 0.4827 - val_acc: 0.8220\n",
      "Epoch 153/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.2107 - acc: 0.9153 - val_loss: 0.4975 - val_acc: 0.8250\n",
      "Epoch 154/1000\n",
      "10000/10000 [==============================] - 4s 423us/step - loss: 0.2064 - acc: 0.9163 - val_loss: 0.5026 - val_acc: 0.8190\n",
      "Epoch 155/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.2119 - acc: 0.9146 - val_loss: 0.4847 - val_acc: 0.8190\n",
      "Epoch 156/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.2084 - acc: 0.9166 - val_loss: 0.5617 - val_acc: 0.8160\n",
      "Epoch 157/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.2084 - acc: 0.9161 - val_loss: 0.5087 - val_acc: 0.8120\n",
      "Epoch 158/1000\n",
      "10000/10000 [==============================] - 4s 423us/step - loss: 0.2068 - acc: 0.9160 - val_loss: 0.5655 - val_acc: 0.8090\n",
      "Epoch 159/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.2012 - acc: 0.9165 - val_loss: 0.5747 - val_acc: 0.8070\n",
      "Epoch 160/1000\n",
      "10000/10000 [==============================] - 4s 423us/step - loss: 0.2010 - acc: 0.9198 - val_loss: 0.5303 - val_acc: 0.8140\n",
      "Epoch 161/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.2010 - acc: 0.9209 - val_loss: 0.5339 - val_acc: 0.8130\n",
      "Epoch 162/1000\n",
      "10000/10000 [==============================] - 4s 427us/step - loss: 0.2000 - acc: 0.9184 - val_loss: 0.5410 - val_acc: 0.8110\n",
      "Epoch 163/1000\n",
      "10000/10000 [==============================] - 4s 424us/step - loss: 0.2007 - acc: 0.9211 - val_loss: 0.5499 - val_acc: 0.8130\n",
      "Epoch 164/1000\n",
      "10000/10000 [==============================] - 4s 438us/step - loss: 0.1978 - acc: 0.9201 - val_loss: 0.5412 - val_acc: 0.8240\n",
      "Epoch 165/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.1972 - acc: 0.9217 - val_loss: 0.5169 - val_acc: 0.8170\n",
      "Epoch 166/1000\n",
      "10000/10000 [==============================] - 4s 443us/step - loss: 0.2002 - acc: 0.9192 - val_loss: 0.5158 - val_acc: 0.8150\n",
      "Epoch 167/1000\n",
      "10000/10000 [==============================] - 4s 427us/step - loss: 0.1920 - acc: 0.9216 - val_loss: 0.5731 - val_acc: 0.8140\n",
      "Epoch 168/1000\n",
      "10000/10000 [==============================] - 5s 478us/step - loss: 0.2007 - acc: 0.9208 - val_loss: 0.5328 - val_acc: 0.8150\n",
      "Epoch 169/1000\n",
      "10000/10000 [==============================] - 5s 518us/step - loss: 0.1933 - acc: 0.9241 - val_loss: 0.5773 - val_acc: 0.8120\n",
      "Epoch 170/1000\n",
      "10000/10000 [==============================] - 5s 484us/step - loss: 0.1938 - acc: 0.9208 - val_loss: 0.5789 - val_acc: 0.8160\n",
      "Epoch 171/1000\n",
      "10000/10000 [==============================] - 6s 563us/step - loss: 0.1866 - acc: 0.9254 - val_loss: 0.5458 - val_acc: 0.8170\n",
      "Epoch 172/1000\n",
      "10000/10000 [==============================] - 5s 526us/step - loss: 0.1846 - acc: 0.9272 - val_loss: 0.5777 - val_acc: 0.8240\n",
      "Epoch 173/1000\n",
      "10000/10000 [==============================] - 5s 513us/step - loss: 0.1934 - acc: 0.9227 - val_loss: 0.5682 - val_acc: 0.8240\n",
      "Epoch 174/1000\n",
      "10000/10000 [==============================] - 5s 454us/step - loss: 0.1869 - acc: 0.9269 - val_loss: 0.5319 - val_acc: 0.8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/1000\n",
      "10000/10000 [==============================] - 4s 419us/step - loss: 0.1913 - acc: 0.9226 - val_loss: 0.5413 - val_acc: 0.8170\n",
      "Epoch 176/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.1891 - acc: 0.9255 - val_loss: 0.5877 - val_acc: 0.8160\n",
      "Epoch 177/1000\n",
      "10000/10000 [==============================] - 5s 455us/step - loss: 0.1879 - acc: 0.9279 - val_loss: 0.5658 - val_acc: 0.8200\n",
      "Epoch 178/1000\n",
      "10000/10000 [==============================] - 5s 465us/step - loss: 0.1881 - acc: 0.9259 - val_loss: 0.5828 - val_acc: 0.8130\n",
      "Epoch 179/1000\n",
      "10000/10000 [==============================] - 4s 424us/step - loss: 0.1895 - acc: 0.9228 - val_loss: 0.5495 - val_acc: 0.8140\n",
      "Epoch 180/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.1874 - acc: 0.9283 - val_loss: 0.5871 - val_acc: 0.8220\n",
      "Epoch 181/1000\n",
      "10000/10000 [==============================] - 4s 406us/step - loss: 0.1856 - acc: 0.9268 - val_loss: 0.5864 - val_acc: 0.8210\n",
      "Epoch 182/1000\n",
      "10000/10000 [==============================] - 4s 428us/step - loss: 0.1936 - acc: 0.9250 - val_loss: 0.5997 - val_acc: 0.8190\n",
      "Epoch 183/1000\n",
      "10000/10000 [==============================] - 5s 464us/step - loss: 0.1822 - acc: 0.9268 - val_loss: 0.6389 - val_acc: 0.8200\n",
      "Epoch 184/1000\n",
      "10000/10000 [==============================] - 4s 447us/step - loss: 0.1860 - acc: 0.9257 - val_loss: 0.5682 - val_acc: 0.8160\n",
      "Epoch 185/1000\n",
      "10000/10000 [==============================] - 5s 455us/step - loss: 0.1875 - acc: 0.9237 - val_loss: 0.6103 - val_acc: 0.8120\n",
      "Epoch 186/1000\n",
      "10000/10000 [==============================] - 5s 454us/step - loss: 0.1777 - acc: 0.9305 - val_loss: 0.6368 - val_acc: 0.8200\n",
      "Epoch 187/1000\n",
      "10000/10000 [==============================] - 4s 433us/step - loss: 0.1830 - acc: 0.9282 - val_loss: 0.6437 - val_acc: 0.8190\n",
      "Epoch 188/1000\n",
      "10000/10000 [==============================] - 4s 434us/step - loss: 0.1748 - acc: 0.9282 - val_loss: 0.5736 - val_acc: 0.8150\n",
      "Epoch 189/1000\n",
      "10000/10000 [==============================] - 4s 413us/step - loss: 0.1799 - acc: 0.9280 - val_loss: 0.6060 - val_acc: 0.8040\n",
      "Epoch 190/1000\n",
      "10000/10000 [==============================] - 4s 424us/step - loss: 0.1722 - acc: 0.9302 - val_loss: 0.5963 - val_acc: 0.8070\n",
      "Epoch 191/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.1732 - acc: 0.9319 - val_loss: 0.7106 - val_acc: 0.8180\n",
      "Epoch 192/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.1780 - acc: 0.9294 - val_loss: 0.6345 - val_acc: 0.8210\n",
      "Epoch 193/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.1734 - acc: 0.9307 - val_loss: 0.6282 - val_acc: 0.8160\n",
      "Epoch 194/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.1794 - acc: 0.9297 - val_loss: 0.6372 - val_acc: 0.8150\n",
      "Epoch 195/1000\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.1724 - acc: 0.9313 - val_loss: 0.6292 - val_acc: 0.8200\n",
      "Epoch 196/1000\n",
      "10000/10000 [==============================] - 4s 428us/step - loss: 0.1661 - acc: 0.9360 - val_loss: 0.6406 - val_acc: 0.8350\n",
      "Epoch 197/1000\n",
      "10000/10000 [==============================] - 4s 433us/step - loss: 0.1671 - acc: 0.9340 - val_loss: 0.6227 - val_acc: 0.8100\n",
      "Epoch 198/1000\n",
      "10000/10000 [==============================] - 4s 421us/step - loss: 0.1748 - acc: 0.9327 - val_loss: 0.6583 - val_acc: 0.8230\n",
      "Epoch 199/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.1746 - acc: 0.9306 - val_loss: 0.6298 - val_acc: 0.8240\n",
      "Epoch 200/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.1639 - acc: 0.9369 - val_loss: 0.6312 - val_acc: 0.8250\n",
      "Epoch 201/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.1696 - acc: 0.9333 - val_loss: 0.6720 - val_acc: 0.8200\n",
      "Epoch 202/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.1741 - acc: 0.9336 - val_loss: 0.6032 - val_acc: 0.8290\n",
      "Epoch 203/1000\n",
      "10000/10000 [==============================] - 4s 423us/step - loss: 0.1682 - acc: 0.9328 - val_loss: 0.6148 - val_acc: 0.8290\n",
      "Epoch 204/1000\n",
      "10000/10000 [==============================] - 4s 423us/step - loss: 0.1686 - acc: 0.9335 - val_loss: 0.6087 - val_acc: 0.8170\n",
      "Epoch 205/1000\n",
      "10000/10000 [==============================] - 4s 424us/step - loss: 0.1699 - acc: 0.9359 - val_loss: 0.5654 - val_acc: 0.8260\n",
      "Epoch 206/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.1574 - acc: 0.9359 - val_loss: 0.6188 - val_acc: 0.8160\n",
      "Epoch 207/1000\n",
      "10000/10000 [==============================] - 4s 423us/step - loss: 0.1661 - acc: 0.9363 - val_loss: 0.7243 - val_acc: 0.8050\n",
      "Epoch 208/1000\n",
      "10000/10000 [==============================] - 4s 421us/step - loss: 0.1605 - acc: 0.9360 - val_loss: 0.6329 - val_acc: 0.8250\n",
      "Epoch 209/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.1590 - acc: 0.9387 - val_loss: 0.6426 - val_acc: 0.8230\n",
      "Epoch 210/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.1589 - acc: 0.9380 - val_loss: 0.6402 - val_acc: 0.8310\n",
      "Epoch 211/1000\n",
      "10000/10000 [==============================] - 4s 439us/step - loss: 0.1640 - acc: 0.9354 - val_loss: 0.5893 - val_acc: 0.8280\n",
      "Epoch 212/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.1614 - acc: 0.9368 - val_loss: 0.6606 - val_acc: 0.8120\n",
      "Epoch 213/1000\n",
      "10000/10000 [==============================] - 4s 437us/step - loss: 0.1619 - acc: 0.9389 - val_loss: 0.6555 - val_acc: 0.8240\n",
      "Epoch 214/1000\n",
      "10000/10000 [==============================] - 4s 447us/step - loss: 0.1530 - acc: 0.9420 - val_loss: 0.6995 - val_acc: 0.8230\n",
      "Epoch 215/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.1627 - acc: 0.9375 - val_loss: 0.6441 - val_acc: 0.8230\n",
      "Epoch 216/1000\n",
      "10000/10000 [==============================] - 4s 439us/step - loss: 0.1591 - acc: 0.9400 - val_loss: 0.6169 - val_acc: 0.8240\n",
      "Epoch 217/1000\n",
      "10000/10000 [==============================] - 4s 423us/step - loss: 0.1683 - acc: 0.9358 - val_loss: 0.6323 - val_acc: 0.8140\n",
      "Epoch 218/1000\n",
      "10000/10000 [==============================] - 4s 428us/step - loss: 0.1533 - acc: 0.9410 - val_loss: 0.6257 - val_acc: 0.8120\n",
      "Epoch 219/1000\n",
      "10000/10000 [==============================] - 4s 424us/step - loss: 0.1612 - acc: 0.9389 - val_loss: 0.6795 - val_acc: 0.8190\n",
      "Epoch 220/1000\n",
      "10000/10000 [==============================] - 4s 432us/step - loss: 0.1670 - acc: 0.9341 - val_loss: 0.6167 - val_acc: 0.8250\n",
      "Epoch 221/1000\n",
      "10000/10000 [==============================] - 4s 427us/step - loss: 0.1547 - acc: 0.9402 - val_loss: 0.6573 - val_acc: 0.8160\n",
      "Epoch 222/1000\n",
      "10000/10000 [==============================] - 4s 428us/step - loss: 0.1523 - acc: 0.9409 - val_loss: 0.6188 - val_acc: 0.8170\n",
      "Epoch 223/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.1572 - acc: 0.9438 - val_loss: 0.6386 - val_acc: 0.8120\n",
      "Epoch 224/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.1522 - acc: 0.9416 - val_loss: 0.6681 - val_acc: 0.8220\n",
      "Epoch 225/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.1521 - acc: 0.9437 - val_loss: 0.7055 - val_acc: 0.8190\n",
      "Epoch 226/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.1492 - acc: 0.9445 - val_loss: 0.6749 - val_acc: 0.8130\n",
      "Epoch 227/1000\n",
      "10000/10000 [==============================] - 4s 437us/step - loss: 0.1568 - acc: 0.9408 - val_loss: 0.7202 - val_acc: 0.8170\n",
      "Epoch 228/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.1449 - acc: 0.9434 - val_loss: 0.7222 - val_acc: 0.8190\n",
      "Epoch 229/1000\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.1532 - acc: 0.9390 - val_loss: 0.6709 - val_acc: 0.8160\n",
      "Epoch 230/1000\n",
      "10000/10000 [==============================] - 4s 428us/step - loss: 0.1527 - acc: 0.9431 - val_loss: 0.6665 - val_acc: 0.8230\n",
      "Epoch 231/1000\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.1512 - acc: 0.9433 - val_loss: 0.6721 - val_acc: 0.8160\n",
      "Epoch 232/1000\n",
      "10000/10000 [==============================] - 4s 428us/step - loss: 0.1447 - acc: 0.9459 - val_loss: 0.7011 - val_acc: 0.8250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/1000\n",
      "10000/10000 [==============================] - 4s 407us/step - loss: 0.1464 - acc: 0.9439 - val_loss: 0.6841 - val_acc: 0.8230\n",
      "Epoch 234/1000\n",
      "10000/10000 [==============================] - 4s 405us/step - loss: 0.1409 - acc: 0.9451 - val_loss: 0.6482 - val_acc: 0.8240\n",
      "Epoch 235/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.1411 - acc: 0.9455 - val_loss: 0.7166 - val_acc: 0.8200\n",
      "Epoch 236/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.1397 - acc: 0.9469 - val_loss: 0.7026 - val_acc: 0.8240\n",
      "Epoch 237/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.1500 - acc: 0.9452 - val_loss: 0.7058 - val_acc: 0.8120\n",
      "Epoch 238/1000\n",
      "10000/10000 [==============================] - 4s 404us/step - loss: 0.1396 - acc: 0.9474 - val_loss: 0.6364 - val_acc: 0.8170\n",
      "Epoch 239/1000\n",
      "10000/10000 [==============================] - 4s 408us/step - loss: 0.1459 - acc: 0.9449 - val_loss: 0.6951 - val_acc: 0.8150\n",
      "Epoch 240/1000\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.1433 - acc: 0.9451 - val_loss: 0.7684 - val_acc: 0.8180\n",
      "Epoch 241/1000\n",
      "10000/10000 [==============================] - 4s 419us/step - loss: 0.1426 - acc: 0.9453 - val_loss: 0.7104 - val_acc: 0.8180\n",
      "Epoch 242/1000\n",
      "10000/10000 [==============================] - 4s 413us/step - loss: 0.1394 - acc: 0.9482 - val_loss: 0.7105 - val_acc: 0.8210\n",
      "Epoch 243/1000\n",
      "10000/10000 [==============================] - 4s 406us/step - loss: 0.1352 - acc: 0.9486 - val_loss: 0.7339 - val_acc: 0.8190\n",
      "Epoch 244/1000\n",
      "10000/10000 [==============================] - 4s 406us/step - loss: 0.1338 - acc: 0.9500 - val_loss: 0.7316 - val_acc: 0.8160\n",
      "Epoch 245/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.1353 - acc: 0.9473 - val_loss: 0.7397 - val_acc: 0.8240\n",
      "Epoch 246/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.1420 - acc: 0.9487 - val_loss: 0.6843 - val_acc: 0.8150\n",
      "Epoch 247/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.1352 - acc: 0.9481 - val_loss: 0.7311 - val_acc: 0.8160\n",
      "Epoch 248/1000\n",
      "10000/10000 [==============================] - 4s 414us/step - loss: 0.1418 - acc: 0.9486 - val_loss: 0.7427 - val_acc: 0.8220\n",
      "Epoch 249/1000\n",
      "10000/10000 [==============================] - 4s 406us/step - loss: 0.1364 - acc: 0.9497 - val_loss: 0.8348 - val_acc: 0.8250\n",
      "Epoch 250/1000\n",
      "10000/10000 [==============================] - 4s 424us/step - loss: 0.1418 - acc: 0.9470 - val_loss: 0.6554 - val_acc: 0.8190\n",
      "Epoch 251/1000\n",
      "10000/10000 [==============================] - 4s 416us/step - loss: 0.1414 - acc: 0.9478 - val_loss: 0.6938 - val_acc: 0.8110\n",
      "Epoch 252/1000\n",
      "10000/10000 [==============================] - 4s 408us/step - loss: 0.1321 - acc: 0.9516 - val_loss: 0.7030 - val_acc: 0.8200\n",
      "Epoch 253/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.1311 - acc: 0.9542 - val_loss: 0.7625 - val_acc: 0.8160\n",
      "Epoch 254/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.1355 - acc: 0.9495 - val_loss: 0.6972 - val_acc: 0.8210\n",
      "Epoch 255/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.1342 - acc: 0.9504 - val_loss: 0.7997 - val_acc: 0.8160\n",
      "Epoch 256/1000\n",
      "10000/10000 [==============================] - 4s 407us/step - loss: 0.1368 - acc: 0.9492 - val_loss: 0.7098 - val_acc: 0.8170\n",
      "Epoch 257/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.1336 - acc: 0.9498 - val_loss: 0.7720 - val_acc: 0.8260\n",
      "Epoch 258/1000\n",
      "10000/10000 [==============================] - ETA: 0s - loss: 0.1326 - acc: 0.951 - 4s 409us/step - loss: 0.1324 - acc: 0.9515 - val_loss: 0.7945 - val_acc: 0.8190\n",
      "Epoch 259/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.1381 - acc: 0.9500 - val_loss: 0.6670 - val_acc: 0.8140\n",
      "Epoch 260/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.1346 - acc: 0.9514 - val_loss: 0.7307 - val_acc: 0.8170\n",
      "Epoch 261/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.1291 - acc: 0.9511 - val_loss: 0.7673 - val_acc: 0.8250\n",
      "Epoch 262/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.1335 - acc: 0.9518 - val_loss: 0.7012 - val_acc: 0.8110\n",
      "Epoch 263/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.1275 - acc: 0.9518 - val_loss: 0.7574 - val_acc: 0.8090\n",
      "Epoch 264/1000\n",
      "10000/10000 [==============================] - 4s 414us/step - loss: 0.1347 - acc: 0.9502 - val_loss: 0.7279 - val_acc: 0.8210\n",
      "Epoch 265/1000\n",
      "10000/10000 [==============================] - 4s 413us/step - loss: 0.1300 - acc: 0.9515 - val_loss: 0.7539 - val_acc: 0.8180\n",
      "Epoch 266/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.1275 - acc: 0.9528 - val_loss: 0.9043 - val_acc: 0.8100\n",
      "Epoch 267/1000\n",
      "10000/10000 [==============================] - 4s 416us/step - loss: 0.1264 - acc: 0.9543 - val_loss: 0.7202 - val_acc: 0.8300\n",
      "Epoch 268/1000\n",
      "10000/10000 [==============================] - 4s 447us/step - loss: 0.1285 - acc: 0.9552 - val_loss: 0.7057 - val_acc: 0.8180\n",
      "Epoch 269/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.1346 - acc: 0.9507 - val_loss: 0.7261 - val_acc: 0.8180\n",
      "Epoch 270/1000\n",
      "10000/10000 [==============================] - 4s 423us/step - loss: 0.1280 - acc: 0.9528 - val_loss: 0.7100 - val_acc: 0.8270\n",
      "Epoch 271/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.1279 - acc: 0.9514 - val_loss: 0.7912 - val_acc: 0.8190\n",
      "Epoch 272/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.1257 - acc: 0.9556 - val_loss: 0.7791 - val_acc: 0.8180\n",
      "Epoch 273/1000\n",
      "10000/10000 [==============================] - 4s 427us/step - loss: 0.1284 - acc: 0.9541 - val_loss: 0.8416 - val_acc: 0.8170\n",
      "Epoch 274/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.1361 - acc: 0.9514 - val_loss: 0.7375 - val_acc: 0.8180\n",
      "Epoch 275/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.1296 - acc: 0.9553 - val_loss: 0.7339 - val_acc: 0.8190\n",
      "Epoch 276/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.1240 - acc: 0.9531 - val_loss: 0.7839 - val_acc: 0.8140\n",
      "Epoch 277/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.1191 - acc: 0.9564 - val_loss: 0.8267 - val_acc: 0.8190\n",
      "Epoch 278/1000\n",
      "10000/10000 [==============================] - 4s 444us/step - loss: 0.1196 - acc: 0.9580 - val_loss: 0.7494 - val_acc: 0.8180\n",
      "Epoch 279/1000\n",
      "10000/10000 [==============================] - 4s 432us/step - loss: 0.1132 - acc: 0.9554 - val_loss: 0.7653 - val_acc: 0.8290\n",
      "Epoch 280/1000\n",
      "10000/10000 [==============================] - 4s 434us/step - loss: 0.1310 - acc: 0.9530 - val_loss: 0.7993 - val_acc: 0.8120\n",
      "Epoch 281/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.1180 - acc: 0.9574 - val_loss: 0.7635 - val_acc: 0.8170\n",
      "Epoch 282/1000\n",
      "10000/10000 [==============================] - 4s 427us/step - loss: 0.1210 - acc: 0.9573 - val_loss: 0.7337 - val_acc: 0.8150\n",
      "Epoch 283/1000\n",
      "10000/10000 [==============================] - 4s 427us/step - loss: 0.1234 - acc: 0.9551 - val_loss: 0.7482 - val_acc: 0.8060\n",
      "Epoch 284/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.1206 - acc: 0.9560 - val_loss: 0.7630 - val_acc: 0.8080\n",
      "Epoch 285/1000\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.1134 - acc: 0.9575 - val_loss: 0.8289 - val_acc: 0.8210\n",
      "Epoch 286/1000\n",
      "10000/10000 [==============================] - 5s 529us/step - loss: 0.1231 - acc: 0.9536 - val_loss: 0.7120 - val_acc: 0.8180\n",
      "Epoch 287/1000\n",
      "10000/10000 [==============================] - 5s 493us/step - loss: 0.1182 - acc: 0.9578 - val_loss: 0.7231 - val_acc: 0.8210\n",
      "Epoch 288/1000\n",
      "10000/10000 [==============================] - 5s 453us/step - loss: 0.1275 - acc: 0.9548 - val_loss: 0.8147 - val_acc: 0.8270\n",
      "Epoch 289/1000\n",
      "10000/10000 [==============================] - 5s 458us/step - loss: 0.1192 - acc: 0.9579 - val_loss: 0.7664 - val_acc: 0.8210\n",
      "Epoch 290/1000\n",
      "10000/10000 [==============================] - 5s 455us/step - loss: 0.1186 - acc: 0.9555 - val_loss: 0.8768 - val_acc: 0.8220\n",
      "Epoch 291/1000\n",
      "10000/10000 [==============================] - 5s 455us/step - loss: 0.1198 - acc: 0.9573 - val_loss: 0.7502 - val_acc: 0.8160\n",
      "Epoch 292/1000\n",
      "10000/10000 [==============================] - 4s 446us/step - loss: 0.1252 - acc: 0.9558 - val_loss: 0.6971 - val_acc: 0.8340\n",
      "Epoch 293/1000\n",
      "10000/10000 [==============================] - 4s 441us/step - loss: 0.1158 - acc: 0.9593 - val_loss: 0.7836 - val_acc: 0.8110\n",
      "Epoch 294/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.1096 - acc: 0.9599 - val_loss: 0.8132 - val_acc: 0.8180\n",
      "Epoch 295/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.1173 - acc: 0.9567 - val_loss: 0.7366 - val_acc: 0.8230\n",
      "Epoch 296/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.1135 - acc: 0.9584 - val_loss: 0.7712 - val_acc: 0.8230\n",
      "Epoch 297/1000\n",
      "10000/10000 [==============================] - 4s 409us/step - loss: 0.1164 - acc: 0.9600 - val_loss: 0.7997 - val_acc: 0.8030\n",
      "Epoch 298/1000\n",
      "10000/10000 [==============================] - 4s 416us/step - loss: 0.1085 - acc: 0.9602 - val_loss: 0.7721 - val_acc: 0.8170\n",
      "Epoch 299/1000\n",
      "10000/10000 [==============================] - 4s 408us/step - loss: 0.1153 - acc: 0.9574 - val_loss: 0.8169 - val_acc: 0.8160\n",
      "Epoch 300/1000\n",
      "10000/10000 [==============================] - 4s 427us/step - loss: 0.1175 - acc: 0.9600 - val_loss: 0.7997 - val_acc: 0.8180\n",
      "Epoch 301/1000\n",
      "10000/10000 [==============================] - 4s 418us/step - loss: 0.1125 - acc: 0.9607 - val_loss: 0.8262 - val_acc: 0.8250\n",
      "Epoch 302/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.1158 - acc: 0.9599 - val_loss: 0.8338 - val_acc: 0.8230\n",
      "Epoch 303/1000\n",
      "10000/10000 [==============================] - 4s 423us/step - loss: 0.1148 - acc: 0.9598 - val_loss: 0.7392 - val_acc: 0.8160\n",
      "Epoch 304/1000\n",
      "10000/10000 [==============================] - 4s 418us/step - loss: 0.1119 - acc: 0.9594 - val_loss: 0.8006 - val_acc: 0.8110\n",
      "Epoch 305/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.1123 - acc: 0.9619 - val_loss: 0.8675 - val_acc: 0.8180\n",
      "Epoch 306/1000\n",
      "10000/10000 [==============================] - 4s 414us/step - loss: 0.1134 - acc: 0.9593 - val_loss: 0.7542 - val_acc: 0.8230\n",
      "Epoch 307/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.1127 - acc: 0.9601 - val_loss: 0.7786 - val_acc: 0.8240\n",
      "Epoch 308/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.1073 - acc: 0.9623 - val_loss: 0.8599 - val_acc: 0.8140\n",
      "Epoch 309/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.1105 - acc: 0.9630 - val_loss: 0.8081 - val_acc: 0.8100\n",
      "Epoch 310/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.1123 - acc: 0.9610 - val_loss: 0.8655 - val_acc: 0.8090\n",
      "Epoch 311/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.1118 - acc: 0.9596 - val_loss: 0.7445 - val_acc: 0.8170\n",
      "Epoch 312/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.1123 - acc: 0.9610 - val_loss: 0.8031 - val_acc: 0.8200\n",
      "Epoch 313/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.1074 - acc: 0.9603 - val_loss: 0.8081 - val_acc: 0.8240\n",
      "Epoch 314/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.1082 - acc: 0.9608 - val_loss: 0.7459 - val_acc: 0.8180\n",
      "Epoch 315/1000\n",
      "10000/10000 [==============================] - 4s 414us/step - loss: 0.1051 - acc: 0.9646 - val_loss: 0.8695 - val_acc: 0.8130\n",
      "Epoch 316/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.1096 - acc: 0.9619 - val_loss: 0.7878 - val_acc: 0.8190\n",
      "Epoch 317/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.0991 - acc: 0.9657 - val_loss: 0.8367 - val_acc: 0.8140\n",
      "Epoch 318/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.1046 - acc: 0.9640 - val_loss: 0.7593 - val_acc: 0.8210\n",
      "Epoch 319/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.1026 - acc: 0.9652 - val_loss: 0.7455 - val_acc: 0.8210\n",
      "Epoch 320/1000\n",
      "10000/10000 [==============================] - 4s 426us/step - loss: 0.1108 - acc: 0.9611 - val_loss: 0.7848 - val_acc: 0.8170\n",
      "Epoch 321/1000\n",
      "10000/10000 [==============================] - 4s 418us/step - loss: 0.1084 - acc: 0.9622 - val_loss: 0.8359 - val_acc: 0.8110\n",
      "Epoch 322/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.1045 - acc: 0.9636 - val_loss: 0.8090 - val_acc: 0.8200\n",
      "Epoch 323/1000\n",
      "10000/10000 [==============================] - 4s 418us/step - loss: 0.0981 - acc: 0.9665 - val_loss: 0.8408 - val_acc: 0.8190\n",
      "Epoch 324/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.0988 - acc: 0.9666 - val_loss: 0.8530 - val_acc: 0.8210\n",
      "Epoch 325/1000\n",
      "10000/10000 [==============================] - 4s 418us/step - loss: 0.1064 - acc: 0.9622 - val_loss: 0.7710 - val_acc: 0.8210\n",
      "Epoch 326/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.1085 - acc: 0.9622 - val_loss: 0.8357 - val_acc: 0.8300\n",
      "Epoch 327/1000\n",
      "10000/10000 [==============================] - 4s 416us/step - loss: 0.1092 - acc: 0.9643 - val_loss: 0.7107 - val_acc: 0.8160\n",
      "Epoch 328/1000\n",
      "10000/10000 [==============================] - 4s 413us/step - loss: 0.0997 - acc: 0.9660 - val_loss: 0.7840 - val_acc: 0.8230\n",
      "Epoch 329/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.1039 - acc: 0.9655 - val_loss: 0.8225 - val_acc: 0.8280\n",
      "Epoch 330/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.1000 - acc: 0.9648 - val_loss: 0.8610 - val_acc: 0.8140\n",
      "Epoch 331/1000\n",
      "10000/10000 [==============================] - 4s 445us/step - loss: 0.0985 - acc: 0.9663 - val_loss: 0.8623 - val_acc: 0.8200\n",
      "Epoch 332/1000\n",
      "10000/10000 [==============================] - 5s 476us/step - loss: 0.0986 - acc: 0.9654 - val_loss: 0.8877 - val_acc: 0.8160\n",
      "Epoch 333/1000\n",
      "10000/10000 [==============================] - 5s 486us/step - loss: 0.0939 - acc: 0.9696 - val_loss: 0.8978 - val_acc: 0.8120\n",
      "Epoch 334/1000\n",
      "10000/10000 [==============================] - 5s 463us/step - loss: 0.0989 - acc: 0.9668 - val_loss: 0.8648 - val_acc: 0.8070\n",
      "Epoch 335/1000\n",
      "10000/10000 [==============================] - 5s 457us/step - loss: 0.1052 - acc: 0.9651 - val_loss: 0.8526 - val_acc: 0.8080\n",
      "Epoch 336/1000\n",
      "10000/10000 [==============================] - 4s 435us/step - loss: 0.1055 - acc: 0.9649 - val_loss: 0.8151 - val_acc: 0.8040\n",
      "Epoch 337/1000\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.0968 - acc: 0.9657 - val_loss: 0.8180 - val_acc: 0.8170\n",
      "Epoch 338/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.0952 - acc: 0.9681 - val_loss: 0.8915 - val_acc: 0.8210\n",
      "Epoch 339/1000\n",
      "10000/10000 [==============================] - 4s 435us/step - loss: 0.1034 - acc: 0.9686 - val_loss: 0.8297 - val_acc: 0.8140\n",
      "Epoch 340/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.0928 - acc: 0.9687 - val_loss: 0.8834 - val_acc: 0.8190\n",
      "Epoch 341/1000\n",
      "10000/10000 [==============================] - 4s 439us/step - loss: 0.0954 - acc: 0.9695 - val_loss: 0.9481 - val_acc: 0.8060\n",
      "Epoch 342/1000\n",
      "10000/10000 [==============================] - 4s 435us/step - loss: 0.1014 - acc: 0.9665 - val_loss: 0.9692 - val_acc: 0.8180\n",
      "Epoch 343/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.1039 - acc: 0.9638 - val_loss: 0.9075 - val_acc: 0.8200\n",
      "Epoch 344/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.1010 - acc: 0.9663 - val_loss: 0.7851 - val_acc: 0.8220\n",
      "Epoch 345/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.1051 - acc: 0.9634 - val_loss: 0.8018 - val_acc: 0.8200\n",
      "Epoch 346/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.0996 - acc: 0.9661 - val_loss: 0.8680 - val_acc: 0.8080\n",
      "Epoch 347/1000\n",
      "10000/10000 [==============================] - ETA: 0s - loss: 0.0954 - acc: 0.967 - 4s 425us/step - loss: 0.0960 - acc: 0.9669 - val_loss: 0.8501 - val_acc: 0.8140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348/1000\n",
      "10000/10000 [==============================] - 4s 402us/step - loss: 0.0979 - acc: 0.9696 - val_loss: 0.8057 - val_acc: 0.8090\n",
      "Epoch 349/1000\n",
      "10000/10000 [==============================] - 4s 404us/step - loss: 0.0966 - acc: 0.9671 - val_loss: 0.9107 - val_acc: 0.8160\n",
      "Epoch 350/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.0930 - acc: 0.9688 - val_loss: 0.9503 - val_acc: 0.8170\n",
      "Epoch 351/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.0943 - acc: 0.9691 - val_loss: 0.9263 - val_acc: 0.8020\n",
      "Epoch 352/1000\n",
      "10000/10000 [==============================] - 4s 398us/step - loss: 0.0914 - acc: 0.9670 - val_loss: 0.9329 - val_acc: 0.8090\n",
      "Epoch 353/1000\n",
      "10000/10000 [==============================] - 4s 404us/step - loss: 0.0833 - acc: 0.9706 - val_loss: 0.9290 - val_acc: 0.8160\n",
      "Epoch 354/1000\n",
      "10000/10000 [==============================] - 4s 398us/step - loss: 0.0902 - acc: 0.9672 - val_loss: 0.9244 - val_acc: 0.8180\n",
      "Epoch 355/1000\n",
      "10000/10000 [==============================] - 4s 397us/step - loss: 0.0939 - acc: 0.9701 - val_loss: 0.8402 - val_acc: 0.8170\n",
      "Epoch 356/1000\n",
      "10000/10000 [==============================] - 4s 407us/step - loss: 0.0934 - acc: 0.9682 - val_loss: 0.9226 - val_acc: 0.8090\n",
      "Epoch 357/1000\n",
      "10000/10000 [==============================] - 4s 411us/step - loss: 0.0897 - acc: 0.9694 - val_loss: 0.8617 - val_acc: 0.8150\n",
      "Epoch 358/1000\n",
      "10000/10000 [==============================] - 4s 408us/step - loss: 0.1039 - acc: 0.9653 - val_loss: 0.8640 - val_acc: 0.8080\n",
      "Epoch 359/1000\n",
      "10000/10000 [==============================] - 4s 408us/step - loss: 0.0940 - acc: 0.9670 - val_loss: 0.8383 - val_acc: 0.8210\n",
      "Epoch 360/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.0887 - acc: 0.9700 - val_loss: 0.9604 - val_acc: 0.8220\n",
      "Epoch 361/1000\n",
      "10000/10000 [==============================] - 4s 402us/step - loss: 0.0960 - acc: 0.9692 - val_loss: 0.9456 - val_acc: 0.8080\n",
      "Epoch 362/1000\n",
      "10000/10000 [==============================] - 4s 407us/step - loss: 0.0815 - acc: 0.9714 - val_loss: 0.9656 - val_acc: 0.8140\n",
      "Epoch 363/1000\n",
      "10000/10000 [==============================] - 4s 403us/step - loss: 0.0869 - acc: 0.9717 - val_loss: 0.9386 - val_acc: 0.8190\n",
      "Epoch 364/1000\n",
      "10000/10000 [==============================] - 4s 405us/step - loss: 0.0954 - acc: 0.9677 - val_loss: 0.8422 - val_acc: 0.8230\n",
      "Epoch 365/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.0880 - acc: 0.9692 - val_loss: 0.9092 - val_acc: 0.8180\n",
      "Epoch 366/1000\n",
      "10000/10000 [==============================] - 4s 411us/step - loss: 0.0911 - acc: 0.9693 - val_loss: 0.8839 - val_acc: 0.8280\n",
      "Epoch 367/1000\n",
      "10000/10000 [==============================] - 4s 407us/step - loss: 0.0932 - acc: 0.9683 - val_loss: 0.9377 - val_acc: 0.8290\n",
      "Epoch 368/1000\n",
      "10000/10000 [==============================] - 4s 405us/step - loss: 0.0922 - acc: 0.9695 - val_loss: 0.8925 - val_acc: 0.8210\n",
      "Epoch 369/1000\n",
      "10000/10000 [==============================] - 4s 419us/step - loss: 0.0846 - acc: 0.9704 - val_loss: 0.9283 - val_acc: 0.8150\n",
      "Epoch 370/1000\n",
      "10000/10000 [==============================] - 4s 414us/step - loss: 0.0907 - acc: 0.9683 - val_loss: 0.9412 - val_acc: 0.8220\n",
      "Epoch 371/1000\n",
      "10000/10000 [==============================] - 4s 407us/step - loss: 0.0934 - acc: 0.9703 - val_loss: 0.8444 - val_acc: 0.8230\n",
      "Epoch 372/1000\n",
      "10000/10000 [==============================] - 4s 407us/step - loss: 0.0920 - acc: 0.9712 - val_loss: 0.8067 - val_acc: 0.8190\n",
      "Epoch 373/1000\n",
      "10000/10000 [==============================] - 4s 405us/step - loss: 0.0936 - acc: 0.9668 - val_loss: 0.7910 - val_acc: 0.8220\n",
      "Epoch 374/1000\n",
      "10000/10000 [==============================] - 4s 424us/step - loss: 0.0855 - acc: 0.9729 - val_loss: 0.8831 - val_acc: 0.8230\n",
      "Epoch 375/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.0851 - acc: 0.9710 - val_loss: 0.9548 - val_acc: 0.8210\n",
      "Epoch 376/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.0883 - acc: 0.9725 - val_loss: 0.8852 - val_acc: 0.8250\n",
      "Epoch 377/1000\n",
      "10000/10000 [==============================] - 4s 408us/step - loss: 0.0850 - acc: 0.9721 - val_loss: 1.0065 - val_acc: 0.8170\n",
      "Epoch 378/1000\n",
      "10000/10000 [==============================] - 4s 405us/step - loss: 0.0850 - acc: 0.9715 - val_loss: 0.9337 - val_acc: 0.8270\n",
      "Epoch 379/1000\n",
      "10000/10000 [==============================] - 4s 407us/step - loss: 0.0893 - acc: 0.9691 - val_loss: 0.9508 - val_acc: 0.8180\n",
      "Epoch 380/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.0919 - acc: 0.9687 - val_loss: 0.8761 - val_acc: 0.8180\n",
      "Epoch 381/1000\n",
      "10000/10000 [==============================] - 4s 408us/step - loss: 0.0790 - acc: 0.9732 - val_loss: 0.9730 - val_acc: 0.8250\n",
      "Epoch 382/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.0885 - acc: 0.9718 - val_loss: 0.9194 - val_acc: 0.8240\n",
      "Epoch 383/1000\n",
      "10000/10000 [==============================] - 4s 439us/step - loss: 0.0906 - acc: 0.9714 - val_loss: 0.8286 - val_acc: 0.8130\n",
      "Epoch 384/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.0991 - acc: 0.9682 - val_loss: 0.8837 - val_acc: 0.8190\n",
      "Epoch 385/1000\n",
      "10000/10000 [==============================] - 4s 416us/step - loss: 0.0932 - acc: 0.9688 - val_loss: 0.9112 - val_acc: 0.8180\n",
      "Epoch 386/1000\n",
      "10000/10000 [==============================] - 4s 413us/step - loss: 0.0848 - acc: 0.9698 - val_loss: 0.9352 - val_acc: 0.8260\n",
      "Epoch 387/1000\n",
      "10000/10000 [==============================] - 4s 414us/step - loss: 0.0822 - acc: 0.9729 - val_loss: 0.8620 - val_acc: 0.8200\n",
      "Epoch 388/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.0925 - acc: 0.9708 - val_loss: 0.8856 - val_acc: 0.8220\n",
      "Epoch 389/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.0822 - acc: 0.9736 - val_loss: 0.9287 - val_acc: 0.8180\n",
      "Epoch 390/1000\n",
      "10000/10000 [==============================] - 4s 418us/step - loss: 0.0852 - acc: 0.9724 - val_loss: 0.9139 - val_acc: 0.8160\n",
      "Epoch 391/1000\n",
      "10000/10000 [==============================] - 4s 432us/step - loss: 0.0814 - acc: 0.9731 - val_loss: 1.0576 - val_acc: 0.8210\n",
      "Epoch 392/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.0821 - acc: 0.9727 - val_loss: 0.9306 - val_acc: 0.8170\n",
      "Epoch 393/1000\n",
      "10000/10000 [==============================] - 4s 418us/step - loss: 0.0854 - acc: 0.9722 - val_loss: 0.9667 - val_acc: 0.8080\n",
      "Epoch 394/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.0762 - acc: 0.9743 - val_loss: 0.8983 - val_acc: 0.8060\n",
      "Epoch 395/1000\n",
      "10000/10000 [==============================] - 4s 411us/step - loss: 0.0816 - acc: 0.9725 - val_loss: 0.8995 - val_acc: 0.8230\n",
      "Epoch 396/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.0879 - acc: 0.9707 - val_loss: 0.9160 - val_acc: 0.8210\n",
      "Epoch 397/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.0811 - acc: 0.9755 - val_loss: 0.9438 - val_acc: 0.8130\n",
      "Epoch 398/1000\n",
      "10000/10000 [==============================] - 4s 407us/step - loss: 0.0794 - acc: 0.9726 - val_loss: 0.8953 - val_acc: 0.8230\n",
      "Epoch 399/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.0792 - acc: 0.9742 - val_loss: 0.9440 - val_acc: 0.8270\n",
      "Epoch 400/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.0748 - acc: 0.9753 - val_loss: 0.9644 - val_acc: 0.8220\n",
      "Epoch 401/1000\n",
      "10000/10000 [==============================] - 4s 436us/step - loss: 0.0821 - acc: 0.9743 - val_loss: 0.9298 - val_acc: 0.8300\n",
      "Epoch 402/1000\n",
      "10000/10000 [==============================] - 5s 455us/step - loss: 0.0748 - acc: 0.9739 - val_loss: 0.9279 - val_acc: 0.8240\n",
      "Epoch 403/1000\n",
      "10000/10000 [==============================] - 5s 452us/step - loss: 0.0818 - acc: 0.9737 - val_loss: 0.9610 - val_acc: 0.8260\n",
      "Epoch 404/1000\n",
      "10000/10000 [==============================] - 5s 465us/step - loss: 0.0801 - acc: 0.9742 - val_loss: 1.0136 - val_acc: 0.8230\n",
      "Epoch 405/1000\n",
      "10000/10000 [==============================] - 5s 486us/step - loss: 0.0700 - acc: 0.9771 - val_loss: 1.0655 - val_acc: 0.8230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406/1000\n",
      "10000/10000 [==============================] - 5s 524us/step - loss: 0.0802 - acc: 0.9745 - val_loss: 0.9236 - val_acc: 0.8120\n",
      "Epoch 407/1000\n",
      "10000/10000 [==============================] - 5s 479us/step - loss: 0.0836 - acc: 0.9741 - val_loss: 0.9318 - val_acc: 0.8280\n",
      "Epoch 408/1000\n",
      "10000/10000 [==============================] - 5s 472us/step - loss: 0.0760 - acc: 0.9764 - val_loss: 0.9170 - val_acc: 0.8290\n",
      "Epoch 409/1000\n",
      "10000/10000 [==============================] - 4s 446us/step - loss: 0.0820 - acc: 0.9742 - val_loss: 0.8652 - val_acc: 0.8200\n",
      "Epoch 410/1000\n",
      "10000/10000 [==============================] - 4s 444us/step - loss: 0.0684 - acc: 0.9776 - val_loss: 1.0159 - val_acc: 0.8220\n",
      "Epoch 411/1000\n",
      "10000/10000 [==============================] - 4s 435us/step - loss: 0.0735 - acc: 0.9742 - val_loss: 0.9446 - val_acc: 0.8180\n",
      "Epoch 412/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.0784 - acc: 0.9747 - val_loss: 0.9169 - val_acc: 0.8190\n",
      "Epoch 413/1000\n",
      "10000/10000 [==============================] - 4s 431us/step - loss: 0.0823 - acc: 0.9714 - val_loss: 0.9276 - val_acc: 0.8270\n",
      "Epoch 414/1000\n",
      "10000/10000 [==============================] - 4s 437us/step - loss: 0.0753 - acc: 0.9774 - val_loss: 0.9577 - val_acc: 0.8240\n",
      "Epoch 415/1000\n",
      "10000/10000 [==============================] - 5s 482us/step - loss: 0.0782 - acc: 0.9742 - val_loss: 0.9847 - val_acc: 0.8270\n",
      "Epoch 416/1000\n",
      "10000/10000 [==============================] - 5s 462us/step - loss: 0.0810 - acc: 0.9734 - val_loss: 0.9817 - val_acc: 0.8190\n",
      "Epoch 417/1000\n",
      "10000/10000 [==============================] - 5s 508us/step - loss: 0.0852 - acc: 0.9738 - val_loss: 0.9650 - val_acc: 0.8260\n",
      "Epoch 418/1000\n",
      "10000/10000 [==============================] - 5s 471us/step - loss: 0.0754 - acc: 0.9741 - val_loss: 0.9764 - val_acc: 0.8150\n",
      "Epoch 419/1000\n",
      "10000/10000 [==============================] - 5s 525us/step - loss: 0.0792 - acc: 0.9765 - val_loss: 0.9730 - val_acc: 0.8210\n",
      "Epoch 420/1000\n",
      "10000/10000 [==============================] - 5s 495us/step - loss: 0.0777 - acc: 0.9743 - val_loss: 1.0215 - val_acc: 0.8300\n",
      "Epoch 421/1000\n",
      "10000/10000 [==============================] - 5s 508us/step - loss: 0.0782 - acc: 0.9760 - val_loss: 0.9420 - val_acc: 0.8160\n",
      "Epoch 422/1000\n",
      "10000/10000 [==============================] - 5s 455us/step - loss: 0.0792 - acc: 0.9730 - val_loss: 0.8688 - val_acc: 0.8210\n",
      "Epoch 423/1000\n",
      "10000/10000 [==============================] - 5s 452us/step - loss: 0.0826 - acc: 0.9738 - val_loss: 0.9635 - val_acc: 0.8220\n",
      "Epoch 424/1000\n",
      "10000/10000 [==============================] - 5s 504us/step - loss: 0.0778 - acc: 0.9734 - val_loss: 1.0068 - val_acc: 0.8190\n",
      "Epoch 425/1000\n",
      "10000/10000 [==============================] - 4s 448us/step - loss: 0.0814 - acc: 0.9738 - val_loss: 0.9986 - val_acc: 0.8210\n",
      "Epoch 426/1000\n",
      "10000/10000 [==============================] - 5s 474us/step - loss: 0.0787 - acc: 0.9754 - val_loss: 0.9335 - val_acc: 0.8200\n",
      "Epoch 427/1000\n",
      "10000/10000 [==============================] - 4s 448us/step - loss: 0.0712 - acc: 0.9777 - val_loss: 1.0730 - val_acc: 0.8300\n",
      "Epoch 428/1000\n",
      "10000/10000 [==============================] - 4s 449us/step - loss: 0.0690 - acc: 0.9773 - val_loss: 1.0027 - val_acc: 0.8240\n",
      "Epoch 429/1000\n",
      "10000/10000 [==============================] - 4s 431us/step - loss: 0.0696 - acc: 0.9778 - val_loss: 1.0869 - val_acc: 0.8210\n",
      "Epoch 430/1000\n",
      "10000/10000 [==============================] - 4s 435us/step - loss: 0.0715 - acc: 0.9775 - val_loss: 1.0482 - val_acc: 0.8260\n",
      "Epoch 431/1000\n",
      "10000/10000 [==============================] - 5s 492us/step - loss: 0.0667 - acc: 0.9796 - val_loss: 1.0663 - val_acc: 0.8260\n",
      "Epoch 432/1000\n",
      "10000/10000 [==============================] - 5s 452us/step - loss: 0.0766 - acc: 0.9746 - val_loss: 0.8826 - val_acc: 0.8240\n",
      "Epoch 433/1000\n",
      "10000/10000 [==============================] - 5s 517us/step - loss: 0.0715 - acc: 0.9770 - val_loss: 0.9227 - val_acc: 0.8220\n",
      "Epoch 434/1000\n",
      "10000/10000 [==============================] - 5s 477us/step - loss: 0.0832 - acc: 0.9764 - val_loss: 0.8783 - val_acc: 0.8130\n",
      "Epoch 435/1000\n",
      "10000/10000 [==============================] - 5s 539us/step - loss: 0.0668 - acc: 0.9796 - val_loss: 0.9568 - val_acc: 0.8210\n",
      "Epoch 436/1000\n",
      "10000/10000 [==============================] - 5s 529us/step - loss: 0.0666 - acc: 0.9785 - val_loss: 0.9550 - val_acc: 0.8240\n",
      "Epoch 437/1000\n",
      "10000/10000 [==============================] - 5s 539us/step - loss: 0.0714 - acc: 0.9769 - val_loss: 0.9613 - val_acc: 0.8300\n",
      "Epoch 438/1000\n",
      "10000/10000 [==============================] - 5s 512us/step - loss: 0.0792 - acc: 0.9749 - val_loss: 0.9274 - val_acc: 0.8280\n",
      "Epoch 439/1000\n",
      "10000/10000 [==============================] - 5s 531us/step - loss: 0.0697 - acc: 0.9774 - val_loss: 0.9394 - val_acc: 0.8220\n",
      "Epoch 440/1000\n",
      "10000/10000 [==============================] - 5s 500us/step - loss: 0.0773 - acc: 0.9771 - val_loss: 0.9950 - val_acc: 0.8190\n",
      "Epoch 441/1000\n",
      "10000/10000 [==============================] - 5s 480us/step - loss: 0.0687 - acc: 0.9764 - val_loss: 1.0521 - val_acc: 0.8320\n",
      "Epoch 442/1000\n",
      "10000/10000 [==============================] - 4s 440us/step - loss: 0.0772 - acc: 0.9772 - val_loss: 0.8735 - val_acc: 0.8260\n",
      "Epoch 443/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.0745 - acc: 0.9766 - val_loss: 0.8604 - val_acc: 0.8210\n",
      "Epoch 444/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.0698 - acc: 0.9776 - val_loss: 0.9596 - val_acc: 0.8310\n",
      "Epoch 445/1000\n",
      "10000/10000 [==============================] - 4s 432us/step - loss: 0.0723 - acc: 0.9768 - val_loss: 0.9049 - val_acc: 0.8160\n",
      "Epoch 446/1000\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.0700 - acc: 0.9778 - val_loss: 1.0636 - val_acc: 0.8310\n",
      "Epoch 447/1000\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.0676 - acc: 0.9782 - val_loss: 0.9707 - val_acc: 0.8290\n",
      "Epoch 448/1000\n",
      "10000/10000 [==============================] - 4s 445us/step - loss: 0.0730 - acc: 0.9776 - val_loss: 0.9960 - val_acc: 0.8300\n",
      "Epoch 449/1000\n",
      "10000/10000 [==============================] - 4s 433us/step - loss: 0.0701 - acc: 0.9761 - val_loss: 0.9329 - val_acc: 0.8250\n",
      "Epoch 450/1000\n",
      "10000/10000 [==============================] - 5s 506us/step - loss: 0.0685 - acc: 0.9770 - val_loss: 0.9201 - val_acc: 0.8160\n",
      "Epoch 451/1000\n",
      "10000/10000 [==============================] - 5s 527us/step - loss: 0.0698 - acc: 0.9778 - val_loss: 1.0992 - val_acc: 0.8240\n",
      "Epoch 452/1000\n",
      "10000/10000 [==============================] - 5s 488us/step - loss: 0.0730 - acc: 0.9764 - val_loss: 0.9658 - val_acc: 0.8300\n",
      "Epoch 453/1000\n",
      "10000/10000 [==============================] - 5s 481us/step - loss: 0.0644 - acc: 0.9787 - val_loss: 1.0463 - val_acc: 0.8320\n",
      "Epoch 454/1000\n",
      "10000/10000 [==============================] - 5s 476us/step - loss: 0.0637 - acc: 0.9801 - val_loss: 1.0841 - val_acc: 0.8290\n",
      "Epoch 455/1000\n",
      "10000/10000 [==============================] - 5s 487us/step - loss: 0.0747 - acc: 0.9782 - val_loss: 0.9015 - val_acc: 0.8340\n",
      "Epoch 456/1000\n",
      "10000/10000 [==============================] - 5s 499us/step - loss: 0.0656 - acc: 0.9790 - val_loss: 1.0365 - val_acc: 0.8250\n",
      "Epoch 457/1000\n",
      "10000/10000 [==============================] - 4s 439us/step - loss: 0.0729 - acc: 0.9771 - val_loss: 0.9864 - val_acc: 0.8230\n",
      "Epoch 458/1000\n",
      "10000/10000 [==============================] - 4s 443us/step - loss: 0.0670 - acc: 0.9797 - val_loss: 1.0268 - val_acc: 0.8400\n",
      "Epoch 459/1000\n",
      "10000/10000 [==============================] - 4s 440us/step - loss: 0.0660 - acc: 0.9773 - val_loss: 1.0258 - val_acc: 0.8310\n",
      "Epoch 460/1000\n",
      "10000/10000 [==============================] - 4s 438us/step - loss: 0.0766 - acc: 0.9795 - val_loss: 0.9224 - val_acc: 0.8250\n",
      "Epoch 461/1000\n",
      "10000/10000 [==============================] - 4s 440us/step - loss: 0.0669 - acc: 0.9791 - val_loss: 1.1180 - val_acc: 0.8330\n",
      "Epoch 462/1000\n",
      "10000/10000 [==============================] - 4s 445us/step - loss: 0.0640 - acc: 0.9801 - val_loss: 1.0250 - val_acc: 0.8250\n",
      "Epoch 463/1000\n",
      "10000/10000 [==============================] - 4s 442us/step - loss: 0.0671 - acc: 0.9782 - val_loss: 1.0460 - val_acc: 0.8270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/1000\n",
      "10000/10000 [==============================] - 4s 409us/step - loss: 0.0632 - acc: 0.9800 - val_loss: 1.0162 - val_acc: 0.8310\n",
      "Epoch 465/1000\n",
      "10000/10000 [==============================] - 4s 407us/step - loss: 0.0731 - acc: 0.9777 - val_loss: 0.9904 - val_acc: 0.8290\n",
      "Epoch 466/1000\n",
      "10000/10000 [==============================] - 4s 405us/step - loss: 0.0685 - acc: 0.9797 - val_loss: 1.0326 - val_acc: 0.8190\n",
      "Epoch 467/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.0633 - acc: 0.9809 - val_loss: 1.0301 - val_acc: 0.8290\n",
      "Epoch 468/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.0693 - acc: 0.9767 - val_loss: 1.0321 - val_acc: 0.8210\n",
      "Epoch 469/1000\n",
      "10000/10000 [==============================] - 4s 408us/step - loss: 0.0647 - acc: 0.9797 - val_loss: 1.0509 - val_acc: 0.8260\n",
      "Epoch 470/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.0628 - acc: 0.9783 - val_loss: 1.1414 - val_acc: 0.8400\n",
      "Epoch 471/1000\n",
      "10000/10000 [==============================] - 4s 413us/step - loss: 0.0644 - acc: 0.9809 - val_loss: 1.0379 - val_acc: 0.8250\n",
      "Epoch 472/1000\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.0663 - acc: 0.9801 - val_loss: 1.0974 - val_acc: 0.8280\n",
      "Epoch 473/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.0677 - acc: 0.9786 - val_loss: 1.1186 - val_acc: 0.8310\n",
      "Epoch 474/1000\n",
      "10000/10000 [==============================] - 4s 421us/step - loss: 0.0631 - acc: 0.9812 - val_loss: 1.0363 - val_acc: 0.8350\n",
      "Epoch 475/1000\n",
      "10000/10000 [==============================] - 4s 423us/step - loss: 0.0695 - acc: 0.9796 - val_loss: 1.0151 - val_acc: 0.8360\n",
      "Epoch 476/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.0672 - acc: 0.9780 - val_loss: 1.0033 - val_acc: 0.8240\n",
      "Epoch 477/1000\n",
      "10000/10000 [==============================] - 4s 413us/step - loss: 0.0682 - acc: 0.9799 - val_loss: 1.1044 - val_acc: 0.8310\n",
      "Epoch 478/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.0605 - acc: 0.9816 - val_loss: 1.0583 - val_acc: 0.8270\n",
      "Epoch 479/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.0743 - acc: 0.9790 - val_loss: 1.0353 - val_acc: 0.8270\n",
      "Epoch 480/1000\n",
      "10000/10000 [==============================] - 4s 413us/step - loss: 0.0559 - acc: 0.9812 - val_loss: 1.1098 - val_acc: 0.8310\n",
      "Epoch 481/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.0568 - acc: 0.9819 - val_loss: 1.1330 - val_acc: 0.8290\n",
      "Epoch 482/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.0723 - acc: 0.9806 - val_loss: 1.0223 - val_acc: 0.8240\n",
      "Epoch 483/1000\n",
      "10000/10000 [==============================] - 4s 428us/step - loss: 0.0707 - acc: 0.9774 - val_loss: 0.9459 - val_acc: 0.8280\n",
      "Epoch 484/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.0620 - acc: 0.9811 - val_loss: 1.0465 - val_acc: 0.8280\n",
      "Epoch 485/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.0706 - acc: 0.9792 - val_loss: 0.9206 - val_acc: 0.8310\n",
      "Epoch 486/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.0686 - acc: 0.9785 - val_loss: 1.0034 - val_acc: 0.8340\n",
      "Epoch 487/1000\n",
      "10000/10000 [==============================] - 4s 413us/step - loss: 0.0574 - acc: 0.9810 - val_loss: 1.0327 - val_acc: 0.8300\n",
      "Epoch 488/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.0672 - acc: 0.9788 - val_loss: 0.9699 - val_acc: 0.8320\n",
      "Epoch 489/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.0663 - acc: 0.9811 - val_loss: 0.9887 - val_acc: 0.8310\n",
      "Epoch 490/1000\n",
      "10000/10000 [==============================] - 4s 409us/step - loss: 0.0540 - acc: 0.9821 - val_loss: 1.2917 - val_acc: 0.8240\n",
      "Epoch 491/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.0773 - acc: 0.9766 - val_loss: 0.9512 - val_acc: 0.8230\n",
      "Epoch 492/1000\n",
      "10000/10000 [==============================] - 4s 416us/step - loss: 0.0601 - acc: 0.9813 - val_loss: 1.0709 - val_acc: 0.8310\n",
      "Epoch 493/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.0583 - acc: 0.9807 - val_loss: 1.1148 - val_acc: 0.8220\n",
      "Epoch 494/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.0674 - acc: 0.9810 - val_loss: 0.9866 - val_acc: 0.8320\n",
      "Epoch 495/1000\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.0679 - acc: 0.9808 - val_loss: 1.0947 - val_acc: 0.8270\n",
      "Epoch 496/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.0691 - acc: 0.9799 - val_loss: 1.0235 - val_acc: 0.8280\n",
      "Epoch 497/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.0711 - acc: 0.9786 - val_loss: 1.0173 - val_acc: 0.8230\n",
      "Epoch 498/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.0672 - acc: 0.9777 - val_loss: 1.0712 - val_acc: 0.8200\n",
      "Epoch 499/1000\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.0621 - acc: 0.9806 - val_loss: 1.1102 - val_acc: 0.8270\n",
      "Epoch 500/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.0672 - acc: 0.9793 - val_loss: 1.0618 - val_acc: 0.8280\n",
      "Epoch 501/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.0646 - acc: 0.9787 - val_loss: 0.9157 - val_acc: 0.8340\n",
      "Epoch 502/1000\n",
      "10000/10000 [==============================] - 4s 419us/step - loss: 0.0738 - acc: 0.9808 - val_loss: 1.0471 - val_acc: 0.8240\n",
      "Epoch 503/1000\n",
      "10000/10000 [==============================] - 4s 418us/step - loss: 0.0611 - acc: 0.9819 - val_loss: 1.0978 - val_acc: 0.8310\n",
      "Epoch 504/1000\n",
      "10000/10000 [==============================] - 4s 419us/step - loss: 0.0697 - acc: 0.9803 - val_loss: 0.9391 - val_acc: 0.8250\n",
      "Epoch 505/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.0664 - acc: 0.9802 - val_loss: 1.0016 - val_acc: 0.8240\n",
      "Epoch 506/1000\n",
      "10000/10000 [==============================] - 4s 433us/step - loss: 0.0694 - acc: 0.9795 - val_loss: 0.9949 - val_acc: 0.8300\n",
      "Epoch 507/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.0670 - acc: 0.9799 - val_loss: 0.9910 - val_acc: 0.8290\n",
      "Epoch 508/1000\n",
      "10000/10000 [==============================] - 4s 441us/step - loss: 0.0578 - acc: 0.9812 - val_loss: 1.0823 - val_acc: 0.8320\n",
      "Epoch 509/1000\n",
      "10000/10000 [==============================] - 4s 426us/step - loss: 0.0709 - acc: 0.9790 - val_loss: 0.9538 - val_acc: 0.8280\n",
      "Epoch 510/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.0663 - acc: 0.9800 - val_loss: 0.9998 - val_acc: 0.8220\n",
      "Epoch 511/1000\n",
      "10000/10000 [==============================] - 4s 428us/step - loss: 0.0550 - acc: 0.9837 - val_loss: 1.0559 - val_acc: 0.8250\n",
      "Epoch 512/1000\n",
      "10000/10000 [==============================] - 4s 424us/step - loss: 0.0694 - acc: 0.9791 - val_loss: 0.8852 - val_acc: 0.8350\n",
      "Epoch 513/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.0669 - acc: 0.9809 - val_loss: 0.9592 - val_acc: 0.8420\n",
      "Epoch 514/1000\n",
      "10000/10000 [==============================] - 4s 434us/step - loss: 0.0669 - acc: 0.9813 - val_loss: 0.9798 - val_acc: 0.8280\n",
      "Epoch 515/1000\n",
      "10000/10000 [==============================] - 4s 423us/step - loss: 0.0632 - acc: 0.9810 - val_loss: 0.9230 - val_acc: 0.8280\n",
      "Epoch 516/1000\n",
      "10000/10000 [==============================] - 4s 427us/step - loss: 0.0670 - acc: 0.9805 - val_loss: 0.9676 - val_acc: 0.8280\n",
      "Epoch 517/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.0630 - acc: 0.9823 - val_loss: 0.9879 - val_acc: 0.8260\n",
      "Epoch 518/1000\n",
      "10000/10000 [==============================] - 4s 437us/step - loss: 0.0611 - acc: 0.9829 - val_loss: 0.9580 - val_acc: 0.8300\n",
      "Epoch 519/1000\n",
      "10000/10000 [==============================] - 4s 428us/step - loss: 0.0667 - acc: 0.9812 - val_loss: 0.9778 - val_acc: 0.8230\n",
      "Epoch 520/1000\n",
      "10000/10000 [==============================] - 4s 432us/step - loss: 0.0519 - acc: 0.9832 - val_loss: 1.1588 - val_acc: 0.8300\n",
      "Epoch 521/1000\n",
      "10000/10000 [==============================] - 4s 439us/step - loss: 0.0624 - acc: 0.9814 - val_loss: 1.0333 - val_acc: 0.8260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 522/1000\n",
      "10000/10000 [==============================] - 4s 407us/step - loss: 0.0571 - acc: 0.9834 - val_loss: 1.0070 - val_acc: 0.8310\n",
      "Epoch 523/1000\n",
      "10000/10000 [==============================] - 4s 409us/step - loss: 0.0553 - acc: 0.9824 - val_loss: 1.1108 - val_acc: 0.8360\n",
      "Epoch 524/1000\n",
      "10000/10000 [==============================] - 4s 409us/step - loss: 0.0664 - acc: 0.9814 - val_loss: 0.9401 - val_acc: 0.8300\n",
      "Epoch 525/1000\n",
      "10000/10000 [==============================] - 4s 427us/step - loss: 0.0664 - acc: 0.9826 - val_loss: 1.0491 - val_acc: 0.8310\n",
      "Epoch 526/1000\n",
      "10000/10000 [==============================] - 4s 422us/step - loss: 0.0543 - acc: 0.9831 - val_loss: 1.0202 - val_acc: 0.8340\n",
      "Epoch 527/1000\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.0598 - acc: 0.9827 - val_loss: 1.0909 - val_acc: 0.8330\n",
      "Epoch 528/1000\n",
      "10000/10000 [==============================] - 4s 411us/step - loss: 0.0632 - acc: 0.9821 - val_loss: 1.0536 - val_acc: 0.8320\n",
      "Epoch 529/1000\n",
      "10000/10000 [==============================] - 4s 414us/step - loss: 0.0653 - acc: 0.9820 - val_loss: 0.9848 - val_acc: 0.8400\n",
      "Epoch 530/1000\n",
      "10000/10000 [==============================] - 4s 409us/step - loss: 0.0610 - acc: 0.9834 - val_loss: 0.9956 - val_acc: 0.8380\n",
      "Epoch 531/1000\n",
      "10000/10000 [==============================] - 4s 410us/step - loss: 0.0592 - acc: 0.9833 - val_loss: 0.9781 - val_acc: 0.8250\n",
      "Epoch 532/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.0567 - acc: 0.9847 - val_loss: 1.1261 - val_acc: 0.8270\n",
      "Epoch 533/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.0600 - acc: 0.9802 - val_loss: 0.9697 - val_acc: 0.8310\n",
      "Epoch 534/1000\n",
      "10000/10000 [==============================] - 4s 414us/step - loss: 0.0659 - acc: 0.9810 - val_loss: 0.9560 - val_acc: 0.8310\n",
      "Epoch 535/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.0498 - acc: 0.9864 - val_loss: 1.0761 - val_acc: 0.8320\n",
      "Epoch 536/1000\n",
      "10000/10000 [==============================] - 4s 414us/step - loss: 0.0629 - acc: 0.9813 - val_loss: 1.0814 - val_acc: 0.8310\n",
      "Epoch 537/1000\n",
      "10000/10000 [==============================] - 4s 415us/step - loss: 0.0520 - acc: 0.9840 - val_loss: 1.0233 - val_acc: 0.8320\n",
      "Epoch 538/1000\n",
      "10000/10000 [==============================] - 4s 418us/step - loss: 0.0632 - acc: 0.9802 - val_loss: 1.0913 - val_acc: 0.8360\n",
      "Epoch 539/1000\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.0635 - acc: 0.9822 - val_loss: 1.0113 - val_acc: 0.8180\n",
      "Epoch 540/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.0634 - acc: 0.9814 - val_loss: 0.9457 - val_acc: 0.8370\n",
      "Epoch 541/1000\n",
      "10000/10000 [==============================] - 4s 418us/step - loss: 0.0607 - acc: 0.9825 - val_loss: 0.9876 - val_acc: 0.8330\n",
      "Epoch 542/1000\n",
      "10000/10000 [==============================] - 4s 412us/step - loss: 0.0552 - acc: 0.9840 - val_loss: 1.0491 - val_acc: 0.8260\n",
      "Epoch 543/1000\n",
      "10000/10000 [==============================] - 4s 419us/step - loss: 0.0565 - acc: 0.9821 - val_loss: 1.0037 - val_acc: 0.8320\n",
      "Epoch 544/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.0547 - acc: 0.9844 - val_loss: 1.1484 - val_acc: 0.8250\n",
      "Epoch 545/1000\n",
      "10000/10000 [==============================] - 4s 413us/step - loss: 0.0641 - acc: 0.9829 - val_loss: 1.0229 - val_acc: 0.8270\n",
      "Epoch 546/1000\n",
      "10000/10000 [==============================] - 4s 413us/step - loss: 0.0616 - acc: 0.9825 - val_loss: 0.9184 - val_acc: 0.8350\n",
      "Epoch 547/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.0632 - acc: 0.9817 - val_loss: 0.9959 - val_acc: 0.8370\n",
      "Epoch 548/1000\n",
      "10000/10000 [==============================] - 4s 417us/step - loss: 0.0655 - acc: 0.9807 - val_loss: 1.0967 - val_acc: 0.8320\n",
      "Epoch 549/1000\n",
      "10000/10000 [==============================] - 4s 419us/step - loss: 0.0611 - acc: 0.9824 - val_loss: 0.9599 - val_acc: 0.8170\n",
      "Epoch 550/1000\n",
      "10000/10000 [==============================] - 4s 416us/step - loss: 0.0571 - acc: 0.9826 - val_loss: 1.0029 - val_acc: 0.8330\n",
      "Epoch 551/1000\n",
      "10000/10000 [==============================] - 4s 427us/step - loss: 0.0624 - acc: 0.9814 - val_loss: 1.0442 - val_acc: 0.8320\n",
      "Epoch 552/1000\n",
      "10000/10000 [==============================] - 4s 424us/step - loss: 0.0519 - acc: 0.9829 - val_loss: 1.0222 - val_acc: 0.8320\n",
      "Epoch 553/1000\n",
      "10000/10000 [==============================] - 4s 432us/step - loss: 0.0625 - acc: 0.9824 - val_loss: 0.9804 - val_acc: 0.8320\n",
      "Epoch 554/1000\n",
      "10000/10000 [==============================] - 5s 471us/step - loss: 0.0584 - acc: 0.9836 - val_loss: 1.0589 - val_acc: 0.8290\n",
      "Epoch 555/1000\n",
      "10000/10000 [==============================] - 5s 488us/step - loss: 0.0583 - acc: 0.9823 - val_loss: 0.9046 - val_acc: 0.8340\n",
      "Epoch 556/1000\n",
      "10000/10000 [==============================] - 5s 458us/step - loss: 0.0575 - acc: 0.9847 - val_loss: 1.0477 - val_acc: 0.8330\n",
      "Epoch 557/1000\n",
      "10000/10000 [==============================] - 4s 443us/step - loss: 0.0588 - acc: 0.9839 - val_loss: 1.0185 - val_acc: 0.8230\n",
      "Epoch 558/1000\n",
      "10000/10000 [==============================] - 4s 439us/step - loss: 0.0601 - acc: 0.9822 - val_loss: 1.0129 - val_acc: 0.8320\n",
      "Epoch 559/1000\n",
      "10000/10000 [==============================] - 4s 433us/step - loss: 0.0603 - acc: 0.9834 - val_loss: 0.9307 - val_acc: 0.8340\n",
      "Epoch 560/1000\n",
      "10000/10000 [==============================] - 4s 433us/step - loss: 0.0521 - acc: 0.9868 - val_loss: 1.0454 - val_acc: 0.8380\n",
      "Epoch 561/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.0624 - acc: 0.9814 - val_loss: 0.9797 - val_acc: 0.8330\n",
      "Epoch 562/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.0597 - acc: 0.9828 - val_loss: 1.0317 - val_acc: 0.8270\n",
      "Epoch 563/1000\n",
      "10000/10000 [==============================] - 4s 427us/step - loss: 0.0513 - acc: 0.9845 - val_loss: 1.1309 - val_acc: 0.8240\n",
      "Epoch 564/1000\n",
      "10000/10000 [==============================] - 4s 435us/step - loss: 0.0515 - acc: 0.9846 - val_loss: 1.0649 - val_acc: 0.8300\n",
      "Epoch 565/1000\n",
      "10000/10000 [==============================] - 4s 435us/step - loss: 0.0531 - acc: 0.9839 - val_loss: 1.2130 - val_acc: 0.8370\n",
      "Epoch 566/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.0617 - acc: 0.9830 - val_loss: 1.0730 - val_acc: 0.8280\n",
      "Epoch 567/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.0623 - acc: 0.9833 - val_loss: 1.0865 - val_acc: 0.8380\n",
      "Epoch 568/1000\n",
      "10000/10000 [==============================] - 4s 441us/step - loss: 0.0604 - acc: 0.9816 - val_loss: 1.0738 - val_acc: 0.8380\n",
      "Epoch 569/1000\n",
      "10000/10000 [==============================] - 4s 435us/step - loss: 0.0584 - acc: 0.9833 - val_loss: 1.1060 - val_acc: 0.8350\n",
      "Epoch 570/1000\n",
      "10000/10000 [==============================] - 5s 458us/step - loss: 0.0576 - acc: 0.9835 - val_loss: 0.9954 - val_acc: 0.8350\n",
      "Epoch 571/1000\n",
      "10000/10000 [==============================] - 5s 450us/step - loss: 0.0527 - acc: 0.9835 - val_loss: 0.9742 - val_acc: 0.8370\n",
      "Epoch 572/1000\n",
      "10000/10000 [==============================] - 4s 448us/step - loss: 0.0470 - acc: 0.9865 - val_loss: 1.1273 - val_acc: 0.8380\n",
      "Epoch 573/1000\n",
      "10000/10000 [==============================] - 5s 461us/step - loss: 0.0641 - acc: 0.9829 - val_loss: 1.0279 - val_acc: 0.8400\n",
      "Epoch 574/1000\n",
      "10000/10000 [==============================] - 5s 494us/step - loss: 0.0569 - acc: 0.9836 - val_loss: 0.9504 - val_acc: 0.8320\n",
      "Epoch 575/1000\n",
      "10000/10000 [==============================] - 5s 524us/step - loss: 0.0557 - acc: 0.9844 - val_loss: 0.9779 - val_acc: 0.8310\n",
      "Epoch 576/1000\n",
      "10000/10000 [==============================] - 5s 501us/step - loss: 0.0566 - acc: 0.9841 - val_loss: 1.1584 - val_acc: 0.8270\n",
      "Epoch 577/1000\n",
      "10000/10000 [==============================] - 5s 507us/step - loss: 0.0545 - acc: 0.9854 - val_loss: 1.0573 - val_acc: 0.8320\n",
      "Epoch 578/1000\n",
      "10000/10000 [==============================] - 5s 460us/step - loss: 0.0676 - acc: 0.9814 - val_loss: 0.9950 - val_acc: 0.8310\n",
      "Epoch 579/1000\n",
      "10000/10000 [==============================] - 5s 468us/step - loss: 0.0503 - acc: 0.9850 - val_loss: 1.1299 - val_acc: 0.8320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 580/1000\n",
      "10000/10000 [==============================] - 4s 439us/step - loss: 0.0595 - acc: 0.9842 - val_loss: 1.0344 - val_acc: 0.8390\n",
      "Epoch 581/1000\n",
      "10000/10000 [==============================] - 4s 441us/step - loss: 0.0510 - acc: 0.9849 - val_loss: 1.2176 - val_acc: 0.8350\n",
      "Epoch 582/1000\n",
      "10000/10000 [==============================] - 4s 448us/step - loss: 0.0586 - acc: 0.9830 - val_loss: 1.1563 - val_acc: 0.8350\n",
      "Epoch 583/1000\n",
      "10000/10000 [==============================] - 4s 443us/step - loss: 0.0607 - acc: 0.9823 - val_loss: 0.9620 - val_acc: 0.8280\n",
      "Epoch 584/1000\n",
      "10000/10000 [==============================] - 5s 467us/step - loss: 0.0585 - acc: 0.9828 - val_loss: 1.0274 - val_acc: 0.8240\n",
      "Epoch 585/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.0478 - acc: 0.9870 - val_loss: 1.1838 - val_acc: 0.8350\n",
      "Epoch 586/1000\n",
      "10000/10000 [==============================] - 4s 420us/step - loss: 0.0573 - acc: 0.9838 - val_loss: 1.0718 - val_acc: 0.8250\n",
      "Epoch 587/1000\n",
      "10000/10000 [==============================] - 4s 445us/step - loss: 0.0523 - acc: 0.9862 - val_loss: 1.0941 - val_acc: 0.8270\n",
      "Epoch 588/1000\n",
      "10000/10000 [==============================] - 4s 437us/step - loss: 0.0627 - acc: 0.9837 - val_loss: 0.9328 - val_acc: 0.8370\n",
      "Epoch 589/1000\n",
      "10000/10000 [==============================] - 5s 455us/step - loss: 0.0607 - acc: 0.9845 - val_loss: 1.2014 - val_acc: 0.8230\n",
      "Epoch 590/1000\n",
      "10000/10000 [==============================] - 5s 457us/step - loss: 0.0627 - acc: 0.9830 - val_loss: 1.0480 - val_acc: 0.8270\n",
      "Epoch 591/1000\n",
      "10000/10000 [==============================] - 5s 489us/step - loss: 0.0562 - acc: 0.9833 - val_loss: 1.1504 - val_acc: 0.8270\n",
      "Epoch 592/1000\n",
      "10000/10000 [==============================] - 5s 455us/step - loss: 0.0526 - acc: 0.9858 - val_loss: 0.9856 - val_acc: 0.8310\n",
      "Epoch 593/1000\n",
      "10000/10000 [==============================] - 4s 424us/step - loss: 0.0531 - acc: 0.9848 - val_loss: 1.1314 - val_acc: 0.8340\n",
      "Epoch 594/1000\n",
      "10000/10000 [==============================] - 4s 443us/step - loss: 0.0650 - acc: 0.9833 - val_loss: 0.9902 - val_acc: 0.8390\n",
      "Epoch 595/1000\n",
      "10000/10000 [==============================] - 4s 436us/step - loss: 0.0524 - acc: 0.9853 - val_loss: 1.0106 - val_acc: 0.8270\n",
      "Epoch 596/1000\n",
      "10000/10000 [==============================] - 4s 442us/step - loss: 0.0590 - acc: 0.9829 - val_loss: 1.0864 - val_acc: 0.8350\n",
      "Epoch 597/1000\n",
      "10000/10000 [==============================] - 4s 442us/step - loss: 0.0561 - acc: 0.9853 - val_loss: 1.0447 - val_acc: 0.8260\n",
      "Epoch 598/1000\n",
      "10000/10000 [==============================] - 4s 436us/step - loss: 0.0592 - acc: 0.9844 - val_loss: 1.0083 - val_acc: 0.8260\n",
      "Epoch 599/1000\n",
      "10000/10000 [==============================] - 5s 499us/step - loss: 0.0548 - acc: 0.9849 - val_loss: 0.9490 - val_acc: 0.8330\n",
      "Epoch 600/1000\n",
      "10000/10000 [==============================] - 4s 431us/step - loss: 0.0546 - acc: 0.9852 - val_loss: 1.0298 - val_acc: 0.8360\n",
      "Epoch 601/1000\n",
      "10000/10000 [==============================] - 4s 423us/step - loss: 0.0515 - acc: 0.9848 - val_loss: 1.1086 - val_acc: 0.8280\n",
      "Epoch 602/1000\n",
      "10000/10000 [==============================] - 4s 432us/step - loss: 0.0600 - acc: 0.9843 - val_loss: 1.1751 - val_acc: 0.8270\n",
      "Epoch 603/1000\n",
      "10000/10000 [==============================] - 4s 438us/step - loss: 0.0461 - acc: 0.9848 - val_loss: 1.1880 - val_acc: 0.8310\n",
      "Epoch 604/1000\n",
      "10000/10000 [==============================] - 4s 445us/step - loss: 0.0581 - acc: 0.9854 - val_loss: 0.9908 - val_acc: 0.8330\n",
      "Epoch 605/1000\n",
      "10000/10000 [==============================] - 4s 437us/step - loss: 0.0614 - acc: 0.9838 - val_loss: 1.2227 - val_acc: 0.8310\n",
      "Epoch 606/1000\n",
      "10000/10000 [==============================] - 4s 442us/step - loss: 0.0563 - acc: 0.9855 - val_loss: 0.9617 - val_acc: 0.8320\n",
      "Epoch 607/1000\n",
      "10000/10000 [==============================] - 5s 505us/step - loss: 0.0476 - acc: 0.9846 - val_loss: 1.1065 - val_acc: 0.8310\n",
      "Epoch 608/1000\n",
      "10000/10000 [==============================] - 4s 445us/step - loss: 0.0527 - acc: 0.9846 - val_loss: 1.1087 - val_acc: 0.8250\n",
      "Epoch 609/1000\n",
      "10000/10000 [==============================] - 4s 434us/step - loss: 0.0638 - acc: 0.9828 - val_loss: 1.0456 - val_acc: 0.8250\n",
      "Epoch 610/1000\n",
      "10000/10000 [==============================] - 4s 449us/step - loss: 0.0600 - acc: 0.9840 - val_loss: 0.9510 - val_acc: 0.8380\n",
      "Epoch 611/1000\n",
      "10000/10000 [==============================] - 5s 457us/step - loss: 0.0577 - acc: 0.9843 - val_loss: 1.0696 - val_acc: 0.8280\n",
      "Epoch 612/1000\n",
      "10000/10000 [==============================] - 5s 455us/step - loss: 0.0586 - acc: 0.9843 - val_loss: 1.0541 - val_acc: 0.8270\n",
      "Epoch 613/1000\n",
      "10000/10000 [==============================] - 5s 453us/step - loss: 0.0502 - acc: 0.9853 - val_loss: 1.1636 - val_acc: 0.8370\n",
      "Epoch 614/1000\n",
      "10000/10000 [==============================] - 5s 485us/step - loss: 0.0558 - acc: 0.9864 - val_loss: 1.0718 - val_acc: 0.8350\n",
      "Epoch 615/1000\n",
      "10000/10000 [==============================] - 5s 469us/step - loss: 0.0559 - acc: 0.9828 - val_loss: 1.0624 - val_acc: 0.8330\n",
      "Epoch 616/1000\n",
      "10000/10000 [==============================] - 4s 438us/step - loss: 0.0539 - acc: 0.9854 - val_loss: 1.0668 - val_acc: 0.8270\n",
      "Epoch 617/1000\n",
      "10000/10000 [==============================] - 4s 438us/step - loss: 0.0546 - acc: 0.9846 - val_loss: 1.1064 - val_acc: 0.8350\n",
      "Epoch 618/1000\n",
      "10000/10000 [==============================] - 5s 464us/step - loss: 0.0638 - acc: 0.9820 - val_loss: 0.9657 - val_acc: 0.8290\n",
      "Epoch 619/1000\n",
      "10000/10000 [==============================] - 5s 454us/step - loss: 0.0542 - acc: 0.9854 - val_loss: 1.0938 - val_acc: 0.8270\n",
      "Epoch 620/1000\n",
      "10000/10000 [==============================] - 5s 504us/step - loss: 0.0423 - acc: 0.9888 - val_loss: 1.1884 - val_acc: 0.8280\n",
      "Epoch 621/1000\n",
      "10000/10000 [==============================] - 5s 455us/step - loss: 0.0448 - acc: 0.9880 - val_loss: 1.0888 - val_acc: 0.8280\n",
      "Epoch 622/1000\n",
      "10000/10000 [==============================] - 5s 459us/step - loss: 0.0506 - acc: 0.9857 - val_loss: 1.1706 - val_acc: 0.8210\n",
      "Epoch 623/1000\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.0494 - acc: 0.9881 - val_loss: 1.0002 - val_acc: 0.8360\n",
      "Epoch 624/1000\n",
      "10000/10000 [==============================] - 4s 437us/step - loss: 0.0572 - acc: 0.9837 - val_loss: 1.1095 - val_acc: 0.8420\n",
      "Epoch 625/1000\n",
      "10000/10000 [==============================] - 5s 453us/step - loss: 0.0622 - acc: 0.9854 - val_loss: 1.1123 - val_acc: 0.8270\n",
      "Epoch 626/1000\n",
      "10000/10000 [==============================] - 4s 444us/step - loss: 0.0485 - acc: 0.9850 - val_loss: 1.0997 - val_acc: 0.8280\n",
      "Epoch 627/1000\n",
      "10000/10000 [==============================] - 5s 452us/step - loss: 0.0491 - acc: 0.9852 - val_loss: 1.1353 - val_acc: 0.8270\n",
      "Epoch 628/1000\n",
      "10000/10000 [==============================] - 5s 475us/step - loss: 0.0468 - acc: 0.9859 - val_loss: 1.1553 - val_acc: 0.8270\n",
      "Epoch 629/1000\n",
      "10000/10000 [==============================] - 5s 470us/step - loss: 0.0566 - acc: 0.9854 - val_loss: 1.1076 - val_acc: 0.8300\n",
      "Epoch 630/1000\n",
      "10000/10000 [==============================] - 5s 462us/step - loss: 0.0499 - acc: 0.9857 - val_loss: 1.1362 - val_acc: 0.8210\n",
      "Epoch 631/1000\n",
      "10000/10000 [==============================] - 5s 459us/step - loss: 0.0590 - acc: 0.9853 - val_loss: 1.0399 - val_acc: 0.8280\n",
      "Epoch 632/1000\n",
      "10000/10000 [==============================] - 5s 484us/step - loss: 0.0528 - acc: 0.9866 - val_loss: 1.0346 - val_acc: 0.8290\n",
      "Epoch 633/1000\n",
      "10000/10000 [==============================] - 5s 463us/step - loss: 0.0538 - acc: 0.9854 - val_loss: 1.0162 - val_acc: 0.8330\n",
      "Epoch 634/1000\n",
      "10000/10000 [==============================] - 5s 488us/step - loss: 0.0454 - acc: 0.9878 - val_loss: 1.0539 - val_acc: 0.8310\n",
      "Epoch 635/1000\n",
      "10000/10000 [==============================] - 5s 464us/step - loss: 0.0605 - acc: 0.9827 - val_loss: 0.9550 - val_acc: 0.8380\n",
      "Epoch 636/1000\n",
      "10000/10000 [==============================] - 5s 501us/step - loss: 0.0540 - acc: 0.9834 - val_loss: 1.1279 - val_acc: 0.8350\n",
      "Epoch 637/1000\n",
      "10000/10000 [==============================] - 5s 487us/step - loss: 0.0581 - acc: 0.9857 - val_loss: 0.9449 - val_acc: 0.8370\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 638/1000\n",
      "10000/10000 [==============================] - 4s 433us/step - loss: 0.0553 - acc: 0.9867 - val_loss: 1.0536 - val_acc: 0.8280\n",
      "Epoch 639/1000\n",
      "10000/10000 [==============================] - 4s 440us/step - loss: 0.0582 - acc: 0.9856 - val_loss: 0.9268 - val_acc: 0.8320\n",
      "Epoch 640/1000\n",
      "10000/10000 [==============================] - 4s 442us/step - loss: 0.0466 - acc: 0.9873 - val_loss: 0.9953 - val_acc: 0.8310\n",
      "Epoch 641/1000\n",
      "10000/10000 [==============================] - 5s 453us/step - loss: 0.0511 - acc: 0.9865 - val_loss: 0.9395 - val_acc: 0.8370\n",
      "Epoch 642/1000\n",
      "10000/10000 [==============================] - 5s 484us/step - loss: 0.0497 - acc: 0.9862 - val_loss: 1.1768 - val_acc: 0.8280\n",
      "Epoch 643/1000\n",
      "10000/10000 [==============================] - 5s 454us/step - loss: 0.0552 - acc: 0.9841 - val_loss: 1.0691 - val_acc: 0.8260\n",
      "Epoch 644/1000\n",
      "10000/10000 [==============================] - 5s 515us/step - loss: 0.0536 - acc: 0.9863 - val_loss: 1.0576 - val_acc: 0.8270\n",
      "Epoch 645/1000\n",
      "10000/10000 [==============================] - 4s 436us/step - loss: 0.0563 - acc: 0.9839 - val_loss: 1.0451 - val_acc: 0.8330\n",
      "Epoch 646/1000\n",
      "10000/10000 [==============================] - 5s 451us/step - loss: 0.0531 - acc: 0.9857 - val_loss: 1.0613 - val_acc: 0.8320\n",
      "Epoch 647/1000\n",
      "10000/10000 [==============================] - 5s 488us/step - loss: 0.0572 - acc: 0.9849 - val_loss: 1.0678 - val_acc: 0.8300\n",
      "Epoch 648/1000\n",
      "10000/10000 [==============================] - 5s 454us/step - loss: 0.0515 - acc: 0.9849 - val_loss: 1.0192 - val_acc: 0.8250\n",
      "Epoch 649/1000\n",
      "10000/10000 [==============================] - 5s 467us/step - loss: 0.0541 - acc: 0.9849 - val_loss: 0.9848 - val_acc: 0.8430\n",
      "Epoch 650/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.0440 - acc: 0.9872 - val_loss: 1.0071 - val_acc: 0.8340\n",
      "Epoch 651/1000\n",
      "10000/10000 [==============================] - 5s 458us/step - loss: 0.0567 - acc: 0.9853 - val_loss: 0.9879 - val_acc: 0.8400\n",
      "Epoch 652/1000\n",
      "10000/10000 [==============================] - 4s 449us/step - loss: 0.0620 - acc: 0.9840 - val_loss: 0.9498 - val_acc: 0.8280\n",
      "Epoch 653/1000\n",
      "10000/10000 [==============================] - 4s 441us/step - loss: 0.0549 - acc: 0.9857 - val_loss: 1.0999 - val_acc: 0.8330\n",
      "Epoch 654/1000\n",
      "10000/10000 [==============================] - 5s 480us/step - loss: 0.0571 - acc: 0.9855 - val_loss: 1.0534 - val_acc: 0.8340\n",
      "Epoch 655/1000\n",
      "10000/10000 [==============================] - 5s 467us/step - loss: 0.0551 - acc: 0.9851 - val_loss: 1.0963 - val_acc: 0.8360\n",
      "Epoch 656/1000\n",
      "10000/10000 [==============================] - 4s 425us/step - loss: 0.0535 - acc: 0.9863 - val_loss: 0.9766 - val_acc: 0.8340\n",
      "Epoch 657/1000\n",
      "10000/10000 [==============================] - 4s 448us/step - loss: 0.0494 - acc: 0.9859 - val_loss: 1.0484 - val_acc: 0.8300\n",
      "Epoch 658/1000\n",
      "10000/10000 [==============================] - 5s 540us/step - loss: 0.0575 - acc: 0.9827 - val_loss: 1.2190 - val_acc: 0.8380\n",
      "Epoch 659/1000\n",
      "10000/10000 [==============================] - 5s 515us/step - loss: 0.0513 - acc: 0.9865 - val_loss: 0.9541 - val_acc: 0.8330\n",
      "Epoch 660/1000\n",
      "10000/10000 [==============================] - 5s 501us/step - loss: 0.0501 - acc: 0.9854 - val_loss: 1.0743 - val_acc: 0.8300\n",
      "Epoch 661/1000\n",
      "10000/10000 [==============================] - 4s 441us/step - loss: 0.0433 - acc: 0.9873 - val_loss: 1.1392 - val_acc: 0.8370\n",
      "Epoch 662/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.0458 - acc: 0.9873 - val_loss: 1.0561 - val_acc: 0.8270\n",
      "Epoch 663/1000\n",
      "10000/10000 [==============================] - 5s 456us/step - loss: 0.0510 - acc: 0.9852 - val_loss: 1.0223 - val_acc: 0.8400\n",
      "Epoch 664/1000\n",
      "10000/10000 [==============================] - 5s 472us/step - loss: 0.0570 - acc: 0.9855 - val_loss: 1.3078 - val_acc: 0.8230\n",
      "Epoch 665/1000\n",
      "10000/10000 [==============================] - 5s 455us/step - loss: 0.0531 - acc: 0.9847 - val_loss: 1.0073 - val_acc: 0.8320\n",
      "Epoch 666/1000\n",
      "10000/10000 [==============================] - 5s 453us/step - loss: 0.0567 - acc: 0.9839 - val_loss: 1.0493 - val_acc: 0.8280\n",
      "Epoch 667/1000\n",
      "10000/10000 [==============================] - 5s 480us/step - loss: 0.0482 - acc: 0.9870 - val_loss: 1.1617 - val_acc: 0.8270\n",
      "Epoch 668/1000\n",
      "10000/10000 [==============================] - 4s 445us/step - loss: 0.0565 - acc: 0.9852 - val_loss: 1.0053 - val_acc: 0.8290\n",
      "Epoch 669/1000\n",
      "10000/10000 [==============================] - 4s 440us/step - loss: 0.0470 - acc: 0.9872 - val_loss: 1.0662 - val_acc: 0.8210\n",
      "Epoch 670/1000\n",
      "10000/10000 [==============================] - 4s 437us/step - loss: 0.0585 - acc: 0.9847 - val_loss: 1.0351 - val_acc: 0.8210\n",
      "Epoch 671/1000\n",
      "10000/10000 [==============================] - 5s 468us/step - loss: 0.0490 - acc: 0.9865 - val_loss: 0.9726 - val_acc: 0.8350\n",
      "Epoch 672/1000\n",
      "10000/10000 [==============================] - 4s 445us/step - loss: 0.0528 - acc: 0.9854 - val_loss: 1.0698 - val_acc: 0.8230\n",
      "Epoch 673/1000\n",
      "10000/10000 [==============================] - 4s 430us/step - loss: 0.0535 - acc: 0.9857 - val_loss: 1.0391 - val_acc: 0.8330\n",
      "Epoch 674/1000\n",
      "10000/10000 [==============================] - 4s 443us/step - loss: 0.0510 - acc: 0.9845 - val_loss: 1.0629 - val_acc: 0.8330\n",
      "Epoch 675/1000\n",
      "10000/10000 [==============================] - 4s 447us/step - loss: 0.0569 - acc: 0.9849 - val_loss: 0.9893 - val_acc: 0.8330\n",
      "Epoch 676/1000\n",
      "10000/10000 [==============================] - 4s 444us/step - loss: 0.0500 - acc: 0.9868 - val_loss: 1.0160 - val_acc: 0.8320\n",
      "Epoch 677/1000\n",
      "10000/10000 [==============================] - 5s 455us/step - loss: 0.0577 - acc: 0.9860 - val_loss: 1.0048 - val_acc: 0.8240\n",
      "Epoch 678/1000\n",
      "10000/10000 [==============================] - 4s 427us/step - loss: 0.0527 - acc: 0.9868 - val_loss: 1.1043 - val_acc: 0.8280\n",
      "Epoch 679/1000\n",
      "10000/10000 [==============================] - 5s 464us/step - loss: 0.0525 - acc: 0.9840 - val_loss: 1.0101 - val_acc: 0.8330\n",
      "Epoch 680/1000\n",
      "10000/10000 [==============================] - 4s 435us/step - loss: 0.0492 - acc: 0.9866 - val_loss: 1.0257 - val_acc: 0.8250\n",
      "Epoch 681/1000\n",
      "10000/10000 [==============================] - 4s 447us/step - loss: 0.0559 - acc: 0.9847 - val_loss: 1.2795 - val_acc: 0.8260\n",
      "Epoch 682/1000\n",
      "10000/10000 [==============================] - 4s 437us/step - loss: 0.0566 - acc: 0.9843 - val_loss: 1.0555 - val_acc: 0.8250\n",
      "Epoch 683/1000\n",
      "10000/10000 [==============================] - 5s 462us/step - loss: 0.0510 - acc: 0.9874 - val_loss: 1.0183 - val_acc: 0.8310\n",
      "Epoch 684/1000\n",
      "10000/10000 [==============================] - 5s 457us/step - loss: 0.0505 - acc: 0.9852 - val_loss: 1.0608 - val_acc: 0.8310\n",
      "Epoch 685/1000\n",
      "10000/10000 [==============================] - 5s 458us/step - loss: 0.0573 - acc: 0.9856 - val_loss: 1.0243 - val_acc: 0.8290\n",
      "Epoch 686/1000\n",
      "10000/10000 [==============================] - 4s 449us/step - loss: 0.0553 - acc: 0.9859 - val_loss: 0.9643 - val_acc: 0.8370\n",
      "Epoch 687/1000\n",
      "10000/10000 [==============================] - 5s 459us/step - loss: 0.0521 - acc: 0.9858 - val_loss: 1.0430 - val_acc: 0.8330\n",
      "Epoch 688/1000\n",
      "10000/10000 [==============================] - 4s 445us/step - loss: 0.0501 - acc: 0.9868 - val_loss: 1.0643 - val_acc: 0.8350\n",
      "Epoch 689/1000\n",
      "10000/10000 [==============================] - 5s 466us/step - loss: 0.0548 - acc: 0.9862 - val_loss: 0.9977 - val_acc: 0.8330\n",
      "Epoch 690/1000\n",
      "10000/10000 [==============================] - 5s 475us/step - loss: 0.0491 - acc: 0.9851 - val_loss: 1.0847 - val_acc: 0.8280\n",
      "Epoch 691/1000\n",
      "10000/10000 [==============================] - 5s 456us/step - loss: 0.0493 - acc: 0.9872 - val_loss: 1.0719 - val_acc: 0.8350\n",
      "Epoch 692/1000\n",
      "10000/10000 [==============================] - 4s 438us/step - loss: 0.0420 - acc: 0.9880 - val_loss: 1.0815 - val_acc: 0.8340\n",
      "Epoch 693/1000\n",
      "10000/10000 [==============================] - 5s 452us/step - loss: 0.0516 - acc: 0.9863 - val_loss: 1.0601 - val_acc: 0.8430\n",
      "Epoch 694/1000\n",
      "10000/10000 [==============================] - 5s 470us/step - loss: 0.0446 - acc: 0.9880 - val_loss: 1.1287 - val_acc: 0.8300\n",
      "Epoch 695/1000\n",
      "10000/10000 [==============================] - 5s 468us/step - loss: 0.0539 - acc: 0.9866 - val_loss: 1.0605 - val_acc: 0.8430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 696/1000\n",
      "10000/10000 [==============================] - 4s 432us/step - loss: 0.0516 - acc: 0.9867 - val_loss: 1.1097 - val_acc: 0.8370\n",
      "Epoch 697/1000\n",
      "10000/10000 [==============================] - 5s 454us/step - loss: 0.0602 - acc: 0.9850 - val_loss: 0.9106 - val_acc: 0.8410\n",
      "Epoch 698/1000\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.0494 - acc: 0.9867 - val_loss: 1.0843 - val_acc: 0.8410\n",
      "Epoch 699/1000\n",
      "10000/10000 [==============================] - 4s 421us/step - loss: 0.0485 - acc: 0.9864 - val_loss: 1.2127 - val_acc: 0.8360\n",
      "Epoch 700/1000\n",
      "10000/10000 [==============================] - 4s 411us/step - loss: 0.0528 - acc: 0.9861 - val_loss: 1.0879 - val_acc: 0.8330\n",
      "Epoch 701/1000\n",
      "10000/10000 [==============================] - 4s 448us/step - loss: 0.0475 - acc: 0.9871 - val_loss: 1.0512 - val_acc: 0.8330\n",
      "Epoch 702/1000\n",
      "10000/10000 [==============================] - 4s 442us/step - loss: 0.0562 - acc: 0.9858 - val_loss: 0.9730 - val_acc: 0.8350\n",
      "Epoch 703/1000\n",
      "10000/10000 [==============================] - 4s 447us/step - loss: 0.0467 - acc: 0.9893 - val_loss: 1.1703 - val_acc: 0.8330\n",
      "Epoch 704/1000\n",
      "10000/10000 [==============================] - 4s 449us/step - loss: 0.0471 - acc: 0.9874 - val_loss: 1.0774 - val_acc: 0.8410\n",
      "Epoch 705/1000\n",
      "10000/10000 [==============================] - 5s 490us/step - loss: 0.0464 - acc: 0.9871 - val_loss: 1.0204 - val_acc: 0.8370\n",
      "Epoch 706/1000\n",
      "10000/10000 [==============================] - 5s 539us/step - loss: 0.0467 - acc: 0.9862 - val_loss: 1.0035 - val_acc: 0.8310\n",
      "Epoch 707/1000\n",
      "10000/10000 [==============================] - 5s 525us/step - loss: 0.0548 - acc: 0.9859 - val_loss: 0.9562 - val_acc: 0.8310\n",
      "Epoch 708/1000\n",
      "10000/10000 [==============================] - 5s 546us/step - loss: 0.0455 - acc: 0.9865 - val_loss: 1.0726 - val_acc: 0.8380\n",
      "Epoch 709/1000\n",
      "10000/10000 [==============================] - 5s 546us/step - loss: 0.0458 - acc: 0.9872 - val_loss: 1.0288 - val_acc: 0.8470\n",
      "Epoch 710/1000\n",
      "10000/10000 [==============================] - 5s 541us/step - loss: 0.0515 - acc: 0.9875 - val_loss: 1.1339 - val_acc: 0.8360\n",
      "Epoch 711/1000\n",
      "10000/10000 [==============================] - 5s 548us/step - loss: 0.0581 - acc: 0.9842 - val_loss: 1.0370 - val_acc: 0.8380\n",
      "Epoch 712/1000\n",
      "10000/10000 [==============================] - 5s 539us/step - loss: 0.0481 - acc: 0.9876 - val_loss: 1.1354 - val_acc: 0.8430\n",
      "Epoch 713/1000\n",
      "10000/10000 [==============================] - 5s 540us/step - loss: 0.0475 - acc: 0.9887 - val_loss: 1.1445 - val_acc: 0.8360\n",
      "Epoch 714/1000\n",
      "10000/10000 [==============================] - 5s 528us/step - loss: 0.0514 - acc: 0.9868 - val_loss: 1.1579 - val_acc: 0.8330\n",
      "Epoch 715/1000\n",
      "10000/10000 [==============================] - 5s 531us/step - loss: 0.0481 - acc: 0.9878 - val_loss: 1.0447 - val_acc: 0.8400\n",
      "Epoch 716/1000\n",
      "10000/10000 [==============================] - 5s 528us/step - loss: 0.0539 - acc: 0.9850 - val_loss: 1.0575 - val_acc: 0.8250\n",
      "Epoch 717/1000\n",
      "10000/10000 [==============================] - 5s 516us/step - loss: 0.0470 - acc: 0.9874 - val_loss: 0.9867 - val_acc: 0.8500\n",
      "Epoch 718/1000\n",
      "10000/10000 [==============================] - 5s 522us/step - loss: 0.0536 - acc: 0.9859 - val_loss: 0.9616 - val_acc: 0.8360\n",
      "Epoch 719/1000\n",
      "10000/10000 [==============================] - 5s 526us/step - loss: 0.0483 - acc: 0.9879 - val_loss: 0.9402 - val_acc: 0.8340\n",
      "Epoch 720/1000\n",
      "10000/10000 [==============================] - 5s 535us/step - loss: 0.0518 - acc: 0.9869 - val_loss: 1.0328 - val_acc: 0.8370\n",
      "Epoch 721/1000\n",
      "10000/10000 [==============================] - 5s 523us/step - loss: 0.0540 - acc: 0.9861 - val_loss: 0.9862 - val_acc: 0.8390\n",
      "Epoch 722/1000\n",
      "10000/10000 [==============================] - 5s 532us/step - loss: 0.0586 - acc: 0.9837 - val_loss: 1.0672 - val_acc: 0.8250\n",
      "Epoch 723/1000\n",
      "10000/10000 [==============================] - 5s 527us/step - loss: 0.0454 - acc: 0.9879 - val_loss: 1.3797 - val_acc: 0.8360\n",
      "Epoch 724/1000\n",
      "10000/10000 [==============================] - 5s 516us/step - loss: 0.0509 - acc: 0.9864 - val_loss: 1.1468 - val_acc: 0.8190\n",
      "Epoch 725/1000\n",
      "10000/10000 [==============================] - 5s 507us/step - loss: 0.0525 - acc: 0.9876 - val_loss: 1.1429 - val_acc: 0.8190\n",
      "Epoch 726/1000\n",
      "10000/10000 [==============================] - 5s 505us/step - loss: 0.0487 - acc: 0.9884 - val_loss: 1.2821 - val_acc: 0.8340\n",
      "Epoch 727/1000\n",
      "10000/10000 [==============================] - 5s 517us/step - loss: 0.0422 - acc: 0.9877 - val_loss: 1.0899 - val_acc: 0.8320\n",
      "Epoch 728/1000\n",
      "10000/10000 [==============================] - 5s 513us/step - loss: 0.0441 - acc: 0.9883 - val_loss: 1.2490 - val_acc: 0.8330\n",
      "Epoch 729/1000\n",
      "10000/10000 [==============================] - 5s 519us/step - loss: 0.0524 - acc: 0.9884 - val_loss: 1.0842 - val_acc: 0.8360\n",
      "Epoch 730/1000\n",
      "10000/10000 [==============================] - 5s 501us/step - loss: 0.0454 - acc: 0.9873 - val_loss: 1.1707 - val_acc: 0.8250\n",
      "Epoch 731/1000\n",
      "10000/10000 [==============================] - 5s 480us/step - loss: 0.0483 - acc: 0.9874 - val_loss: 1.0772 - val_acc: 0.8380\n",
      "Epoch 732/1000\n",
      "10000/10000 [==============================] - 5s 503us/step - loss: 0.0475 - acc: 0.9882 - val_loss: 1.0799 - val_acc: 0.8400\n",
      "Epoch 733/1000\n",
      "10000/10000 [==============================] - 5s 516us/step - loss: 0.0463 - acc: 0.9869 - val_loss: 1.0790 - val_acc: 0.8310\n",
      "Epoch 734/1000\n",
      "10000/10000 [==============================] - 5s 524us/step - loss: 0.0447 - acc: 0.9878 - val_loss: 1.2792 - val_acc: 0.8300\n",
      "Epoch 735/1000\n",
      "10000/10000 [==============================] - 5s 514us/step - loss: 0.0566 - acc: 0.9861 - val_loss: 1.2048 - val_acc: 0.8340\n",
      "Epoch 736/1000\n",
      "10000/10000 [==============================] - 5s 516us/step - loss: 0.0502 - acc: 0.9880 - val_loss: 1.2960 - val_acc: 0.8320\n",
      "Epoch 737/1000\n",
      "10000/10000 [==============================] - 5s 514us/step - loss: 0.0451 - acc: 0.9876 - val_loss: 1.1780 - val_acc: 0.8290\n",
      "Epoch 738/1000\n",
      "10000/10000 [==============================] - 5s 504us/step - loss: 0.0501 - acc: 0.9887 - val_loss: 1.0595 - val_acc: 0.8290\n",
      "Epoch 739/1000\n",
      "10000/10000 [==============================] - 5s 496us/step - loss: 0.0611 - acc: 0.9846 - val_loss: 1.1347 - val_acc: 0.8240\n",
      "Epoch 740/1000\n",
      "10000/10000 [==============================] - 5s 513us/step - loss: 0.0447 - acc: 0.9873 - val_loss: 1.1482 - val_acc: 0.8350\n",
      "Epoch 741/1000\n",
      "10000/10000 [==============================] - 5s 509us/step - loss: 0.0438 - acc: 0.9881 - val_loss: 1.1724 - val_acc: 0.8220\n",
      "Epoch 742/1000\n",
      "10000/10000 [==============================] - 5s 475us/step - loss: 0.0440 - acc: 0.9876 - val_loss: 1.2027 - val_acc: 0.8330\n",
      "Epoch 743/1000\n",
      "10000/10000 [==============================] - 5s 509us/step - loss: 0.0509 - acc: 0.9863 - val_loss: 1.2434 - val_acc: 0.8290\n",
      "Epoch 744/1000\n",
      "10000/10000 [==============================] - 5s 524us/step - loss: 0.0506 - acc: 0.9874 - val_loss: 1.1959 - val_acc: 0.8370\n",
      "Epoch 745/1000\n",
      "10000/10000 [==============================] - 5s 520us/step - loss: 0.0537 - acc: 0.9863 - val_loss: 1.1215 - val_acc: 0.8380\n",
      "Epoch 746/1000\n",
      "10000/10000 [==============================] - 5s 516us/step - loss: 0.0532 - acc: 0.9874 - val_loss: 1.1115 - val_acc: 0.8260\n",
      "Epoch 747/1000\n",
      "10000/10000 [==============================] - 5s 509us/step - loss: 0.0496 - acc: 0.9876 - val_loss: 1.0798 - val_acc: 0.8320\n",
      "Epoch 748/1000\n",
      "10000/10000 [==============================] - 5s 510us/step - loss: 0.0413 - acc: 0.9885 - val_loss: 1.1168 - val_acc: 0.8170\n",
      "Epoch 749/1000\n",
      "10000/10000 [==============================] - 5s 506us/step - loss: 0.0583 - acc: 0.9867 - val_loss: 1.1294 - val_acc: 0.8230\n",
      "Epoch 750/1000\n",
      "10000/10000 [==============================] - 5s 511us/step - loss: 0.0513 - acc: 0.9880 - val_loss: 1.1293 - val_acc: 0.8280\n",
      "Epoch 751/1000\n",
      "10000/10000 [==============================] - 5s 503us/step - loss: 0.0473 - acc: 0.9880 - val_loss: 0.9823 - val_acc: 0.8490\n",
      "Epoch 752/1000\n",
      "10000/10000 [==============================] - 5s 489us/step - loss: 0.0502 - acc: 0.9862 - val_loss: 1.3010 - val_acc: 0.8230\n",
      "Epoch 753/1000\n",
      "10000/10000 [==============================] - 5s 485us/step - loss: 0.0490 - acc: 0.9885 - val_loss: 1.1476 - val_acc: 0.8380\n",
      "Epoch 754/1000\n",
      "10000/10000 [==============================] - 5s 544us/step - loss: 0.0554 - acc: 0.9871 - val_loss: 1.0576 - val_acc: 0.8320\n",
      "Epoch 755/1000\n",
      "10000/10000 [==============================] - 6s 562us/step - loss: 0.0409 - acc: 0.9886 - val_loss: 1.0604 - val_acc: 0.8380\n",
      "Epoch 756/1000\n",
      "10000/10000 [==============================] - 6s 565us/step - loss: 0.0407 - acc: 0.9896 - val_loss: 1.2540 - val_acc: 0.8370\n",
      "Epoch 757/1000\n",
      "10000/10000 [==============================] - 6s 566us/step - loss: 0.0510 - acc: 0.9866 - val_loss: 1.1486 - val_acc: 0.8300\n",
      "Epoch 758/1000\n",
      "10000/10000 [==============================] - 6s 567us/step - loss: 0.0517 - acc: 0.9853 - val_loss: 1.0518 - val_acc: 0.8300\n",
      "Epoch 759/1000\n",
      "10000/10000 [==============================] - 6s 563us/step - loss: 0.0501 - acc: 0.9870 - val_loss: 1.1332 - val_acc: 0.8290\n",
      "Epoch 760/1000\n",
      "10000/10000 [==============================] - 6s 561us/step - loss: 0.0499 - acc: 0.9863 - val_loss: 1.1582 - val_acc: 0.8300\n",
      "Epoch 761/1000\n",
      "10000/10000 [==============================] - 6s 562us/step - loss: 0.0411 - acc: 0.9887 - val_loss: 1.0822 - val_acc: 0.8280\n",
      "Epoch 762/1000\n",
      "10000/10000 [==============================] - 6s 558us/step - loss: 0.0460 - acc: 0.9865 - val_loss: 1.0717 - val_acc: 0.8290\n",
      "Epoch 763/1000\n",
      "10000/10000 [==============================] - 6s 561us/step - loss: 0.0402 - acc: 0.9892 - val_loss: 1.1082 - val_acc: 0.8380\n",
      "Epoch 764/1000\n",
      "10000/10000 [==============================] - 6s 560us/step - loss: 0.0478 - acc: 0.9879 - val_loss: 1.0391 - val_acc: 0.8430\n",
      "Epoch 765/1000\n",
      "10000/10000 [==============================] - 5s 549us/step - loss: 0.0504 - acc: 0.9868 - val_loss: 1.1572 - val_acc: 0.8320\n",
      "Epoch 766/1000\n",
      "10000/10000 [==============================] - 5s 531us/step - loss: 0.0550 - acc: 0.9857 - val_loss: 1.1367 - val_acc: 0.8310\n",
      "Epoch 767/1000\n",
      "10000/10000 [==============================] - 5s 547us/step - loss: 0.0466 - acc: 0.9883 - val_loss: 0.9850 - val_acc: 0.8400\n",
      "Epoch 768/1000\n",
      "10000/10000 [==============================] - 5s 531us/step - loss: 0.0479 - acc: 0.9863 - val_loss: 1.1169 - val_acc: 0.8390\n",
      "Epoch 769/1000\n",
      "10000/10000 [==============================] - 5s 525us/step - loss: 0.0462 - acc: 0.9884 - val_loss: 1.0774 - val_acc: 0.8350\n",
      "Epoch 770/1000\n",
      "10000/10000 [==============================] - 5s 516us/step - loss: 0.0490 - acc: 0.9886 - val_loss: 1.1199 - val_acc: 0.8360\n",
      "Epoch 771/1000\n",
      "10000/10000 [==============================] - 6s 551us/step - loss: 0.0400 - acc: 0.9882 - val_loss: 1.0410 - val_acc: 0.8430\n",
      "Epoch 772/1000\n",
      "10000/10000 [==============================] - 5s 531us/step - loss: 0.0444 - acc: 0.9890 - val_loss: 0.9839 - val_acc: 0.8480\n",
      "Epoch 773/1000\n",
      "10000/10000 [==============================] - 5s 539us/step - loss: 0.0466 - acc: 0.9865 - val_loss: 1.2484 - val_acc: 0.8350\n",
      "Epoch 774/1000\n",
      "10000/10000 [==============================] - 6s 555us/step - loss: 0.0483 - acc: 0.9883 - val_loss: 1.1317 - val_acc: 0.8380\n",
      "Epoch 775/1000\n",
      "10000/10000 [==============================] - 5s 542us/step - loss: 0.0562 - acc: 0.9844 - val_loss: 1.1408 - val_acc: 0.8300\n",
      "Epoch 776/1000\n",
      "10000/10000 [==============================] - 5s 485us/step - loss: 0.0434 - acc: 0.9877 - val_loss: 1.2642 - val_acc: 0.8340\n",
      "Epoch 777/1000\n",
      "10000/10000 [==============================] - 5s 510us/step - loss: 0.0514 - acc: 0.9890 - val_loss: 1.1092 - val_acc: 0.8290\n",
      "Epoch 778/1000\n",
      "10000/10000 [==============================] - 5s 542us/step - loss: 0.0447 - acc: 0.9883 - val_loss: 1.0764 - val_acc: 0.8330\n",
      "Epoch 779/1000\n",
      "10000/10000 [==============================] - 5s 527us/step - loss: 0.0525 - acc: 0.9861 - val_loss: 1.0445 - val_acc: 0.8360\n",
      "Epoch 780/1000\n",
      "10000/10000 [==============================] - 5s 521us/step - loss: 0.0500 - acc: 0.9866 - val_loss: 1.0193 - val_acc: 0.8320\n",
      "Epoch 781/1000\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 0.0508 - acc: 0.9858 - val_loss: 1.0159 - val_acc: 0.8280\n",
      "Epoch 782/1000\n",
      "10000/10000 [==============================] - 5s 521us/step - loss: 0.0467 - acc: 0.9866 - val_loss: 0.9717 - val_acc: 0.8370\n",
      "Epoch 783/1000\n",
      "10000/10000 [==============================] - 5s 516us/step - loss: 0.0519 - acc: 0.9867 - val_loss: 1.2082 - val_acc: 0.8320\n",
      "Epoch 784/1000\n",
      "10000/10000 [==============================] - 5s 516us/step - loss: 0.0503 - acc: 0.9868 - val_loss: 1.0532 - val_acc: 0.8280\n",
      "Epoch 785/1000\n",
      "10000/10000 [==============================] - 5s 512us/step - loss: 0.0524 - acc: 0.9879 - val_loss: 1.0296 - val_acc: 0.8320\n",
      "Epoch 786/1000\n",
      "10000/10000 [==============================] - 5s 513us/step - loss: 0.0479 - acc: 0.9874 - val_loss: 1.3571 - val_acc: 0.8320\n",
      "Epoch 787/1000\n",
      "10000/10000 [==============================] - 5s 514us/step - loss: 0.0498 - acc: 0.9878 - val_loss: 1.0841 - val_acc: 0.8310\n",
      "Epoch 788/1000\n",
      "10000/10000 [==============================] - 5s 517us/step - loss: 0.0433 - acc: 0.9882 - val_loss: 1.1283 - val_acc: 0.8320\n",
      "Epoch 789/1000\n",
      "10000/10000 [==============================] - 5s 513us/step - loss: 0.0408 - acc: 0.9875 - val_loss: 1.1080 - val_acc: 0.8300\n",
      "Epoch 790/1000\n",
      "10000/10000 [==============================] - 5s 521us/step - loss: 0.0466 - acc: 0.9883 - val_loss: 1.2326 - val_acc: 0.8320\n",
      "Epoch 791/1000\n",
      "10000/10000 [==============================] - 5s 518us/step - loss: 0.0488 - acc: 0.9871 - val_loss: 1.3714 - val_acc: 0.8280\n",
      "Epoch 792/1000\n",
      "10000/10000 [==============================] - 5s 505us/step - loss: 0.0432 - acc: 0.9880 - val_loss: 0.9669 - val_acc: 0.8390\n",
      "Epoch 793/1000\n",
      "10000/10000 [==============================] - 5s 495us/step - loss: 0.0467 - acc: 0.9876 - val_loss: 1.0946 - val_acc: 0.8310\n",
      "Epoch 794/1000\n",
      "10000/10000 [==============================] - 5s 501us/step - loss: 0.0442 - acc: 0.9882 - val_loss: 1.1615 - val_acc: 0.8280\n",
      "Epoch 795/1000\n",
      "10000/10000 [==============================] - 5s 494us/step - loss: 0.0449 - acc: 0.9888 - val_loss: 1.0751 - val_acc: 0.8360\n",
      "Epoch 796/1000\n",
      "10000/10000 [==============================] - 5s 513us/step - loss: 0.0443 - acc: 0.9887 - val_loss: 1.1779 - val_acc: 0.8420\n",
      "Epoch 797/1000\n",
      "10000/10000 [==============================] - 5s 506us/step - loss: 0.0486 - acc: 0.9869 - val_loss: 1.1342 - val_acc: 0.8410\n",
      "Epoch 798/1000\n",
      "10000/10000 [==============================] - 5s 500us/step - loss: 0.0498 - acc: 0.9877 - val_loss: 1.1249 - val_acc: 0.8360\n",
      "Epoch 799/1000\n",
      "10000/10000 [==============================] - 5s 505us/step - loss: 0.0434 - acc: 0.9887 - val_loss: 1.0736 - val_acc: 0.8310\n",
      "Epoch 800/1000\n",
      "10000/10000 [==============================] - 5s 499us/step - loss: 0.0485 - acc: 0.9876 - val_loss: 1.1488 - val_acc: 0.8340\n",
      "Epoch 801/1000\n",
      "10000/10000 [==============================] - 5s 507us/step - loss: 0.0425 - acc: 0.9890 - val_loss: 1.0547 - val_acc: 0.8470\n",
      "Epoch 802/1000\n",
      "10000/10000 [==============================] - 5s 501us/step - loss: 0.0427 - acc: 0.9889 - val_loss: 1.1941 - val_acc: 0.8360\n",
      "Epoch 803/1000\n",
      "10000/10000 [==============================] - 5s 512us/step - loss: 0.0444 - acc: 0.9887 - val_loss: 1.1230 - val_acc: 0.8360\n",
      "Epoch 804/1000\n",
      "10000/10000 [==============================] - 5s 495us/step - loss: 0.0428 - acc: 0.9893 - val_loss: 1.2700 - val_acc: 0.8320\n",
      "Epoch 805/1000\n",
      "10000/10000 [==============================] - 5s 498us/step - loss: 0.0531 - acc: 0.9860 - val_loss: 1.0454 - val_acc: 0.8340\n",
      "Epoch 806/1000\n",
      "10000/10000 [==============================] - 5s 484us/step - loss: 0.0498 - acc: 0.9870 - val_loss: 1.1514 - val_acc: 0.8370\n",
      "Epoch 807/1000\n",
      "10000/10000 [==============================] - 5s 483us/step - loss: 0.0498 - acc: 0.9877 - val_loss: 1.0053 - val_acc: 0.8390\n",
      "Epoch 808/1000\n",
      "10000/10000 [==============================] - 5s 503us/step - loss: 0.0502 - acc: 0.9882 - val_loss: 1.0941 - val_acc: 0.8290\n",
      "Epoch 809/1000\n",
      "10000/10000 [==============================] - 5s 498us/step - loss: 0.0519 - acc: 0.9863 - val_loss: 1.0013 - val_acc: 0.8310\n",
      "Epoch 810/1000\n",
      "10000/10000 [==============================] - 5s 489us/step - loss: 0.0430 - acc: 0.9891 - val_loss: 1.0714 - val_acc: 0.8400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 811/1000\n",
      "10000/10000 [==============================] - 6s 563us/step - loss: 0.0509 - acc: 0.9891 - val_loss: 1.0893 - val_acc: 0.8250\n",
      "Epoch 812/1000\n",
      "10000/10000 [==============================] - 6s 566us/step - loss: 0.0432 - acc: 0.9895 - val_loss: 1.2615 - val_acc: 0.8270\n",
      "Epoch 813/1000\n",
      "10000/10000 [==============================] - 6s 565us/step - loss: 0.0445 - acc: 0.9888 - val_loss: 1.1236 - val_acc: 0.8330\n",
      "Epoch 814/1000\n",
      "10000/10000 [==============================] - 6s 570us/step - loss: 0.0532 - acc: 0.9869 - val_loss: 1.1349 - val_acc: 0.8340\n",
      "Epoch 815/1000\n",
      "10000/10000 [==============================] - 6s 565us/step - loss: 0.0565 - acc: 0.9869 - val_loss: 0.9861 - val_acc: 0.8380\n",
      "Epoch 816/1000\n",
      "10000/10000 [==============================] - 6s 570us/step - loss: 0.0429 - acc: 0.9892 - val_loss: 1.0363 - val_acc: 0.8340\n",
      "Epoch 817/1000\n",
      "10000/10000 [==============================] - 6s 556us/step - loss: 0.0456 - acc: 0.9873 - val_loss: 0.9880 - val_acc: 0.8420\n",
      "Epoch 818/1000\n",
      "10000/10000 [==============================] - 5s 539us/step - loss: 0.0444 - acc: 0.9875 - val_loss: 1.0941 - val_acc: 0.8350\n",
      "Epoch 819/1000\n",
      "10000/10000 [==============================] - 6s 555us/step - loss: 0.0448 - acc: 0.9879 - val_loss: 1.0472 - val_acc: 0.8360\n",
      "Epoch 820/1000\n",
      "10000/10000 [==============================] - 5s 550us/step - loss: 0.0427 - acc: 0.9893 - val_loss: 1.0186 - val_acc: 0.8410\n",
      "Epoch 821/1000\n",
      "10000/10000 [==============================] - 6s 553us/step - loss: 0.0426 - acc: 0.9898 - val_loss: 1.0857 - val_acc: 0.8320\n",
      "Epoch 822/1000\n",
      "10000/10000 [==============================] - 6s 552us/step - loss: 0.0638 - acc: 0.9860 - val_loss: 1.2690 - val_acc: 0.8320\n",
      "Epoch 823/1000\n",
      "10000/10000 [==============================] - 5s 545us/step - loss: 0.0438 - acc: 0.9884 - val_loss: 1.0194 - val_acc: 0.8400\n",
      "Epoch 824/1000\n",
      "10000/10000 [==============================] - 6s 556us/step - loss: 0.0487 - acc: 0.9877 - val_loss: 1.0553 - val_acc: 0.8320\n",
      "Epoch 825/1000\n",
      "10000/10000 [==============================] - 5s 541us/step - loss: 0.0568 - acc: 0.9864 - val_loss: 1.0178 - val_acc: 0.8340\n",
      "Epoch 826/1000\n",
      "10000/10000 [==============================] - 5s 546us/step - loss: 0.0480 - acc: 0.9884 - val_loss: 1.0158 - val_acc: 0.8340\n",
      "Epoch 827/1000\n",
      "10000/10000 [==============================] - 6s 557us/step - loss: 0.0478 - acc: 0.9878 - val_loss: 1.0032 - val_acc: 0.8390\n",
      "Epoch 828/1000\n",
      "10000/10000 [==============================] - 6s 551us/step - loss: 0.0477 - acc: 0.9885 - val_loss: 1.1147 - val_acc: 0.8370\n",
      "Epoch 829/1000\n",
      "10000/10000 [==============================] - 5s 540us/step - loss: 0.0485 - acc: 0.9887 - val_loss: 1.1677 - val_acc: 0.8350\n",
      "Epoch 830/1000\n",
      "10000/10000 [==============================] - 5s 541us/step - loss: 0.0503 - acc: 0.9883 - val_loss: 1.1929 - val_acc: 0.8420\n",
      "Epoch 831/1000\n",
      "10000/10000 [==============================] - 5s 507us/step - loss: 0.0433 - acc: 0.9894 - val_loss: 1.1531 - val_acc: 0.8340\n",
      "Epoch 832/1000\n",
      "10000/10000 [==============================] - 5s 528us/step - loss: 0.0474 - acc: 0.9869 - val_loss: 1.1151 - val_acc: 0.8360\n",
      "Epoch 833/1000\n",
      "10000/10000 [==============================] - 5s 541us/step - loss: 0.0462 - acc: 0.9882 - val_loss: 1.0502 - val_acc: 0.8350\n",
      "Epoch 834/1000\n",
      "10000/10000 [==============================] - 5s 537us/step - loss: 0.0560 - acc: 0.9871 - val_loss: 0.9839 - val_acc: 0.8340\n",
      "Epoch 835/1000\n",
      "10000/10000 [==============================] - 5s 535us/step - loss: 0.0418 - acc: 0.9886 - val_loss: 1.2166 - val_acc: 0.8440\n",
      "Epoch 836/1000\n",
      "10000/10000 [==============================] - 5s 527us/step - loss: 0.0480 - acc: 0.9879 - val_loss: 1.1662 - val_acc: 0.8480\n",
      "Epoch 837/1000\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 0.0549 - acc: 0.9894 - val_loss: 1.1653 - val_acc: 0.8380\n",
      "Epoch 838/1000\n",
      "10000/10000 [==============================] - 5s 524us/step - loss: 0.0348 - acc: 0.9918 - val_loss: 1.1186 - val_acc: 0.8360\n",
      "Epoch 839/1000\n",
      "10000/10000 [==============================] - 5s 527us/step - loss: 0.0411 - acc: 0.9886 - val_loss: 1.1118 - val_acc: 0.8320\n",
      "Epoch 840/1000\n",
      "10000/10000 [==============================] - 5s 513us/step - loss: 0.0368 - acc: 0.9886 - val_loss: 0.9913 - val_acc: 0.8350\n",
      "Epoch 841/1000\n",
      "10000/10000 [==============================] - 5s 521us/step - loss: 0.0393 - acc: 0.9890 - val_loss: 1.1444 - val_acc: 0.8310\n",
      "Epoch 842/1000\n",
      "10000/10000 [==============================] - 5s 516us/step - loss: 0.0450 - acc: 0.9885 - val_loss: 0.9589 - val_acc: 0.8320\n",
      "Epoch 843/1000\n",
      "10000/10000 [==============================] - 5s 510us/step - loss: 0.0589 - acc: 0.9859 - val_loss: 0.9489 - val_acc: 0.8410\n",
      "Epoch 844/1000\n",
      "10000/10000 [==============================] - 5s 520us/step - loss: 0.0432 - acc: 0.9891 - val_loss: 0.9386 - val_acc: 0.8410\n",
      "Epoch 845/1000\n",
      "10000/10000 [==============================] - 5s 518us/step - loss: 0.0522 - acc: 0.9877 - val_loss: 0.9948 - val_acc: 0.8290\n",
      "Epoch 846/1000\n",
      "10000/10000 [==============================] - 5s 514us/step - loss: 0.0481 - acc: 0.9872 - val_loss: 1.0048 - val_acc: 0.8320\n",
      "Epoch 847/1000\n",
      "10000/10000 [==============================] - 5s 510us/step - loss: 0.0435 - acc: 0.9881 - val_loss: 1.0169 - val_acc: 0.8390\n",
      "Epoch 848/1000\n",
      "10000/10000 [==============================] - 5s 533us/step - loss: 0.0449 - acc: 0.9892 - val_loss: 1.2053 - val_acc: 0.8360\n",
      "Epoch 849/1000\n",
      "10000/10000 [==============================] - 5s 511us/step - loss: 0.0457 - acc: 0.9891 - val_loss: 1.0931 - val_acc: 0.8360\n",
      "Epoch 850/1000\n",
      "10000/10000 [==============================] - 5s 522us/step - loss: 0.0483 - acc: 0.9883 - val_loss: 1.1489 - val_acc: 0.8340\n",
      "Epoch 851/1000\n",
      "10000/10000 [==============================] - 5s 514us/step - loss: 0.0458 - acc: 0.9868 - val_loss: 1.0960 - val_acc: 0.8410\n",
      "Epoch 852/1000\n",
      "10000/10000 [==============================] - 5s 501us/step - loss: 0.0439 - acc: 0.9879 - val_loss: 1.0850 - val_acc: 0.8380\n",
      "Epoch 853/1000\n",
      "10000/10000 [==============================] - 5s 502us/step - loss: 0.0503 - acc: 0.9881 - val_loss: 1.0823 - val_acc: 0.8380\n",
      "Epoch 854/1000\n",
      "10000/10000 [==============================] - 5s 512us/step - loss: 0.0478 - acc: 0.9883 - val_loss: 1.1114 - val_acc: 0.8290\n",
      "Epoch 855/1000\n",
      "10000/10000 [==============================] - 5s 512us/step - loss: 0.0461 - acc: 0.9881 - val_loss: 1.0069 - val_acc: 0.8420\n",
      "Epoch 856/1000\n",
      "10000/10000 [==============================] - 5s 512us/step - loss: 0.0489 - acc: 0.9863 - val_loss: 1.0993 - val_acc: 0.8360\n",
      "Epoch 857/1000\n",
      "10000/10000 [==============================] - 5s 499us/step - loss: 0.0530 - acc: 0.9877 - val_loss: 0.9940 - val_acc: 0.8460\n",
      "Epoch 858/1000\n",
      "10000/10000 [==============================] - 5s 514us/step - loss: 0.0403 - acc: 0.9889 - val_loss: 1.2325 - val_acc: 0.8270\n",
      "Epoch 859/1000\n",
      "10000/10000 [==============================] - 5s 506us/step - loss: 0.0452 - acc: 0.9884 - val_loss: 1.0392 - val_acc: 0.8430\n",
      "Epoch 860/1000\n",
      "10000/10000 [==============================] - 5s 501us/step - loss: 0.0488 - acc: 0.9875 - val_loss: 1.0606 - val_acc: 0.8370\n",
      "Epoch 861/1000\n",
      "10000/10000 [==============================] - 5s 502us/step - loss: 0.0439 - acc: 0.9886 - val_loss: 1.0637 - val_acc: 0.8390\n",
      "Epoch 862/1000\n",
      "10000/10000 [==============================] - 5s 512us/step - loss: 0.0395 - acc: 0.9895 - val_loss: 1.5154 - val_acc: 0.8280\n",
      "Epoch 863/1000\n",
      "10000/10000 [==============================] - 5s 504us/step - loss: 0.0413 - acc: 0.9885 - val_loss: 1.0609 - val_acc: 0.8380\n",
      "Epoch 864/1000\n",
      "10000/10000 [==============================] - 5s 500us/step - loss: 0.0428 - acc: 0.9884 - val_loss: 1.0543 - val_acc: 0.8250\n",
      "Epoch 865/1000\n",
      "10000/10000 [==============================] - 5s 503us/step - loss: 0.0476 - acc: 0.9875 - val_loss: 0.9784 - val_acc: 0.8440\n",
      "Epoch 866/1000\n",
      "10000/10000 [==============================] - 5s 492us/step - loss: 0.0507 - acc: 0.9861 - val_loss: 0.9905 - val_acc: 0.8370\n",
      "Epoch 867/1000\n",
      "10000/10000 [==============================] - 5s 492us/step - loss: 0.0510 - acc: 0.9864 - val_loss: 1.0817 - val_acc: 0.8330\n",
      "Epoch 868/1000\n",
      "10000/10000 [==============================] - 5s 498us/step - loss: 0.0491 - acc: 0.9877 - val_loss: 0.9194 - val_acc: 0.8420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 869/1000\n",
      "10000/10000 [==============================] - 6s 553us/step - loss: 0.0461 - acc: 0.9873 - val_loss: 0.9034 - val_acc: 0.8420\n",
      "Epoch 870/1000\n",
      "10000/10000 [==============================] - 6s 567us/step - loss: 0.0473 - acc: 0.9886 - val_loss: 0.9979 - val_acc: 0.8410\n",
      "Epoch 871/1000\n",
      "10000/10000 [==============================] - 6s 559us/step - loss: 0.0505 - acc: 0.9885 - val_loss: 0.9221 - val_acc: 0.8510\n",
      "Epoch 872/1000\n",
      "10000/10000 [==============================] - 6s 565us/step - loss: 0.0461 - acc: 0.9875 - val_loss: 1.1774 - val_acc: 0.8400\n",
      "Epoch 873/1000\n",
      "10000/10000 [==============================] - 6s 574us/step - loss: 0.0466 - acc: 0.9886 - val_loss: 0.9632 - val_acc: 0.8530\n",
      "Epoch 874/1000\n",
      "10000/10000 [==============================] - 6s 554us/step - loss: 0.0507 - acc: 0.9877 - val_loss: 0.9334 - val_acc: 0.8510\n",
      "Epoch 875/1000\n",
      "10000/10000 [==============================] - 6s 559us/step - loss: 0.0350 - acc: 0.9913 - val_loss: 1.0270 - val_acc: 0.8540\n",
      "Epoch 876/1000\n",
      "10000/10000 [==============================] - 5s 545us/step - loss: 0.0419 - acc: 0.9892 - val_loss: 1.0716 - val_acc: 0.8430\n",
      "Epoch 877/1000\n",
      "10000/10000 [==============================] - 6s 552us/step - loss: 0.0395 - acc: 0.9882 - val_loss: 1.0578 - val_acc: 0.8380\n",
      "Epoch 878/1000\n",
      "10000/10000 [==============================] - 6s 555us/step - loss: 0.0437 - acc: 0.9895 - val_loss: 1.0793 - val_acc: 0.8400\n",
      "Epoch 879/1000\n",
      "10000/10000 [==============================] - 6s 560us/step - loss: 0.0456 - acc: 0.9895 - val_loss: 1.0998 - val_acc: 0.8440\n",
      "Epoch 880/1000\n",
      "10000/10000 [==============================] - 6s 554us/step - loss: 0.0571 - acc: 0.9863 - val_loss: 1.1162 - val_acc: 0.8430\n",
      "Epoch 881/1000\n",
      "10000/10000 [==============================] - 6s 551us/step - loss: 0.0455 - acc: 0.9890 - val_loss: 1.0572 - val_acc: 0.8400\n",
      "Epoch 882/1000\n",
      "10000/10000 [==============================] - 6s 557us/step - loss: 0.0491 - acc: 0.9879 - val_loss: 1.0857 - val_acc: 0.8320\n",
      "Epoch 883/1000\n",
      "10000/10000 [==============================] - 6s 550us/step - loss: 0.0476 - acc: 0.9866 - val_loss: 1.0506 - val_acc: 0.8410\n",
      "Epoch 884/1000\n",
      "10000/10000 [==============================] - 5s 548us/step - loss: 0.0452 - acc: 0.9874 - val_loss: 0.9999 - val_acc: 0.8320\n",
      "Epoch 885/1000\n",
      "10000/10000 [==============================] - 5s 549us/step - loss: 0.0418 - acc: 0.9889 - val_loss: 1.2741 - val_acc: 0.8410\n",
      "Epoch 886/1000\n",
      "10000/10000 [==============================] - 6s 554us/step - loss: 0.0434 - acc: 0.9879 - val_loss: 1.0514 - val_acc: 0.8400\n",
      "Epoch 887/1000\n",
      "10000/10000 [==============================] - 5s 546us/step - loss: 0.0532 - acc: 0.9877 - val_loss: 0.9564 - val_acc: 0.8430\n",
      "Epoch 888/1000\n",
      "10000/10000 [==============================] - 5s 506us/step - loss: 0.0464 - acc: 0.9883 - val_loss: 0.9349 - val_acc: 0.8430\n",
      "Epoch 889/1000\n",
      "10000/10000 [==============================] - 5s 527us/step - loss: 0.0407 - acc: 0.9886 - val_loss: 1.0877 - val_acc: 0.8480\n",
      "Epoch 890/1000\n",
      "10000/10000 [==============================] - 5s 543us/step - loss: 0.0441 - acc: 0.9887 - val_loss: 1.1051 - val_acc: 0.8330\n",
      "Epoch 891/1000\n",
      "10000/10000 [==============================] - 5s 547us/step - loss: 0.0465 - acc: 0.9890 - val_loss: 1.1147 - val_acc: 0.8390\n",
      "Epoch 892/1000\n",
      "10000/10000 [==============================] - 5s 540us/step - loss: 0.0500 - acc: 0.9872 - val_loss: 1.0184 - val_acc: 0.8400\n",
      "Epoch 893/1000\n",
      "10000/10000 [==============================] - 5s 541us/step - loss: 0.0485 - acc: 0.9866 - val_loss: 1.0450 - val_acc: 0.8430\n",
      "Epoch 894/1000\n",
      "10000/10000 [==============================] - 5s 541us/step - loss: 0.0510 - acc: 0.9868 - val_loss: 0.9990 - val_acc: 0.8350\n",
      "Epoch 895/1000\n",
      "10000/10000 [==============================] - 5s 540us/step - loss: 0.0399 - acc: 0.9886 - val_loss: 0.9987 - val_acc: 0.8470\n",
      "Epoch 896/1000\n",
      "10000/10000 [==============================] - 5s 534us/step - loss: 0.0481 - acc: 0.9891 - val_loss: 0.9597 - val_acc: 0.8530\n",
      "Epoch 897/1000\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 0.0448 - acc: 0.9893 - val_loss: 1.1436 - val_acc: 0.8400\n",
      "Epoch 898/1000\n",
      "10000/10000 [==============================] - 5s 540us/step - loss: 0.0428 - acc: 0.9884 - val_loss: 1.1946 - val_acc: 0.8380\n",
      "Epoch 899/1000\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 0.0511 - acc: 0.9880 - val_loss: 1.0402 - val_acc: 0.8380\n",
      "Epoch 900/1000\n",
      "10000/10000 [==============================] - 5s 527us/step - loss: 0.0450 - acc: 0.9875 - val_loss: 1.0072 - val_acc: 0.8400\n",
      "Epoch 901/1000\n",
      "10000/10000 [==============================] - 5s 514us/step - loss: 0.0452 - acc: 0.9889 - val_loss: 1.1150 - val_acc: 0.8460\n",
      "Epoch 902/1000\n",
      "10000/10000 [==============================] - 5s 514us/step - loss: 0.0425 - acc: 0.9879 - val_loss: 1.1004 - val_acc: 0.8420\n",
      "Epoch 903/1000\n",
      "10000/10000 [==============================] - 5s 531us/step - loss: 0.0452 - acc: 0.9877 - val_loss: 1.1174 - val_acc: 0.8460\n",
      "Epoch 904/1000\n",
      "10000/10000 [==============================] - 5s 508us/step - loss: 0.0440 - acc: 0.9878 - val_loss: 1.0249 - val_acc: 0.8460\n",
      "Epoch 905/1000\n",
      "10000/10000 [==============================] - 5s 525us/step - loss: 0.0383 - acc: 0.9892 - val_loss: 1.2508 - val_acc: 0.8480\n",
      "Epoch 906/1000\n",
      "10000/10000 [==============================] - 5s 491us/step - loss: 0.0480 - acc: 0.9887 - val_loss: 1.1243 - val_acc: 0.8280\n",
      "Epoch 907/1000\n",
      "10000/10000 [==============================] - 5s 508us/step - loss: 0.0469 - acc: 0.9889 - val_loss: 1.2355 - val_acc: 0.8250\n",
      "Epoch 908/1000\n",
      "10000/10000 [==============================] - 5s 486us/step - loss: 0.0408 - acc: 0.9896 - val_loss: 1.1432 - val_acc: 0.8370\n",
      "Epoch 909/1000\n",
      "10000/10000 [==============================] - 5s 464us/step - loss: 0.0488 - acc: 0.9862 - val_loss: 0.9962 - val_acc: 0.8450\n",
      "Epoch 910/1000\n",
      "10000/10000 [==============================] - 5s 458us/step - loss: 0.0424 - acc: 0.9894 - val_loss: 1.1908 - val_acc: 0.8400\n",
      "Epoch 911/1000\n",
      "10000/10000 [==============================] - 6s 583us/step - loss: 0.0467 - acc: 0.9883 - val_loss: 1.0986 - val_acc: 0.8450\n",
      "Epoch 912/1000\n",
      "10000/10000 [==============================] - 5s 506us/step - loss: 0.0521 - acc: 0.9868 - val_loss: 0.9498 - val_acc: 0.8390\n",
      "Epoch 913/1000\n",
      "10000/10000 [==============================] - 5s 517us/step - loss: 0.0327 - acc: 0.9908 - val_loss: 0.9983 - val_acc: 0.8400\n",
      "Epoch 914/1000\n",
      "10000/10000 [==============================] - 5s 520us/step - loss: 0.0503 - acc: 0.9888 - val_loss: 1.2001 - val_acc: 0.8300\n",
      "Epoch 915/1000\n",
      "10000/10000 [==============================] - 5s 531us/step - loss: 0.0487 - acc: 0.9894 - val_loss: 1.0221 - val_acc: 0.8470\n",
      "Epoch 916/1000\n",
      "10000/10000 [==============================] - 6s 558us/step - loss: 0.0497 - acc: 0.9879 - val_loss: 1.0388 - val_acc: 0.8410\n",
      "Epoch 917/1000\n",
      "10000/10000 [==============================] - 5s 509us/step - loss: 0.0436 - acc: 0.9904 - val_loss: 1.0172 - val_acc: 0.8530\n",
      "Epoch 918/1000\n",
      "10000/10000 [==============================] - 5s 515us/step - loss: 0.0444 - acc: 0.9888 - val_loss: 1.1382 - val_acc: 0.8410\n",
      "Epoch 919/1000\n",
      "10000/10000 [==============================] - 5s 512us/step - loss: 0.0386 - acc: 0.9900 - val_loss: 1.1007 - val_acc: 0.8400\n",
      "Epoch 920/1000\n",
      "10000/10000 [==============================] - 5s 515us/step - loss: 0.0504 - acc: 0.9880 - val_loss: 0.9658 - val_acc: 0.8430\n",
      "Epoch 921/1000\n",
      "10000/10000 [==============================] - 5s 504us/step - loss: 0.0401 - acc: 0.9895 - val_loss: 1.1046 - val_acc: 0.8440\n",
      "Epoch 922/1000\n",
      "10000/10000 [==============================] - 5s 508us/step - loss: 0.0411 - acc: 0.9896 - val_loss: 1.0829 - val_acc: 0.8500\n",
      "Epoch 923/1000\n",
      "10000/10000 [==============================] - 5s 503us/step - loss: 0.0397 - acc: 0.9901 - val_loss: 1.0578 - val_acc: 0.8450\n",
      "Epoch 924/1000\n",
      "10000/10000 [==============================] - 5s 485us/step - loss: 0.0510 - acc: 0.9883 - val_loss: 1.2824 - val_acc: 0.8340\n",
      "Epoch 925/1000\n",
      "10000/10000 [==============================] - 5s 491us/step - loss: 0.0505 - acc: 0.9888 - val_loss: 1.0876 - val_acc: 0.8400\n",
      "Epoch 926/1000\n",
      "10000/10000 [==============================] - 5s 493us/step - loss: 0.0430 - acc: 0.9902 - val_loss: 1.1161 - val_acc: 0.8420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 927/1000\n",
      "10000/10000 [==============================] - 6s 560us/step - loss: 0.0389 - acc: 0.9905 - val_loss: 1.1998 - val_acc: 0.8340\n",
      "Epoch 928/1000\n",
      "10000/10000 [==============================] - 5s 537us/step - loss: 0.0478 - acc: 0.9877 - val_loss: 1.0007 - val_acc: 0.8430\n",
      "Epoch 929/1000\n",
      "10000/10000 [==============================] - 6s 559us/step - loss: 0.0473 - acc: 0.9881 - val_loss: 1.1049 - val_acc: 0.8410\n",
      "Epoch 930/1000\n",
      "10000/10000 [==============================] - 6s 576us/step - loss: 0.0511 - acc: 0.9875 - val_loss: 0.9832 - val_acc: 0.8430\n",
      "Epoch 931/1000\n",
      "10000/10000 [==============================] - 6s 566us/step - loss: 0.0477 - acc: 0.9889 - val_loss: 1.0410 - val_acc: 0.8340\n",
      "Epoch 932/1000\n",
      "10000/10000 [==============================] - 5s 549us/step - loss: 0.0388 - acc: 0.9905 - val_loss: 1.0710 - val_acc: 0.8470\n",
      "Epoch 933/1000\n",
      "10000/10000 [==============================] - 6s 560us/step - loss: 0.0463 - acc: 0.9877 - val_loss: 1.0430 - val_acc: 0.8370\n",
      "Epoch 934/1000\n",
      "10000/10000 [==============================] - 5s 524us/step - loss: 0.0410 - acc: 0.9892 - val_loss: 1.1183 - val_acc: 0.8290\n",
      "Epoch 935/1000\n",
      "10000/10000 [==============================] - 5s 535us/step - loss: 0.0420 - acc: 0.9903 - val_loss: 1.0996 - val_acc: 0.8340\n",
      "Epoch 936/1000\n",
      "10000/10000 [==============================] - 6s 553us/step - loss: 0.0381 - acc: 0.9894 - val_loss: 1.0309 - val_acc: 0.8540\n",
      "Epoch 937/1000\n",
      "10000/10000 [==============================] - 6s 555us/step - loss: 0.0447 - acc: 0.9889 - val_loss: 1.0110 - val_acc: 0.8480\n",
      "Epoch 938/1000\n",
      "10000/10000 [==============================] - 5s 545us/step - loss: 0.0497 - acc: 0.9890 - val_loss: 1.0121 - val_acc: 0.8440\n",
      "Epoch 939/1000\n",
      "10000/10000 [==============================] - 5s 537us/step - loss: 0.0419 - acc: 0.9889 - val_loss: 0.9933 - val_acc: 0.8520\n",
      "Epoch 940/1000\n",
      "10000/10000 [==============================] - 5s 536us/step - loss: 0.0464 - acc: 0.9901 - val_loss: 1.0444 - val_acc: 0.8450\n",
      "Epoch 941/1000\n",
      "10000/10000 [==============================] - 5s 520us/step - loss: 0.0557 - acc: 0.9864 - val_loss: 0.9275 - val_acc: 0.8460\n",
      "Epoch 942/1000\n",
      "10000/10000 [==============================] - 5s 513us/step - loss: 0.0410 - acc: 0.9898 - val_loss: 0.9965 - val_acc: 0.8500\n",
      "Epoch 943/1000\n",
      "10000/10000 [==============================] - 5s 548us/step - loss: 0.0404 - acc: 0.9891 - val_loss: 0.9537 - val_acc: 0.8480\n",
      "Epoch 944/1000\n",
      "10000/10000 [==============================] - 5s 538us/step - loss: 0.0423 - acc: 0.9898 - val_loss: 0.9870 - val_acc: 0.8470\n",
      "Epoch 945/1000\n",
      "10000/10000 [==============================] - 5s 519us/step - loss: 0.0463 - acc: 0.9895 - val_loss: 1.0405 - val_acc: 0.8530\n",
      "Epoch 946/1000\n",
      "10000/10000 [==============================] - 5s 521us/step - loss: 0.0378 - acc: 0.9909 - val_loss: 1.0465 - val_acc: 0.8530\n",
      "Epoch 947/1000\n",
      "10000/10000 [==============================] - 5s 528us/step - loss: 0.0471 - acc: 0.9900 - val_loss: 1.1137 - val_acc: 0.8400\n",
      "Epoch 948/1000\n",
      "10000/10000 [==============================] - 5s 533us/step - loss: 0.0407 - acc: 0.9906 - val_loss: 1.0184 - val_acc: 0.8470\n",
      "Epoch 949/1000\n",
      "10000/10000 [==============================] - 5s 533us/step - loss: 0.0538 - acc: 0.9875 - val_loss: 1.0712 - val_acc: 0.8380\n",
      "Epoch 950/1000\n",
      "10000/10000 [==============================] - 5s 523us/step - loss: 0.0469 - acc: 0.9870 - val_loss: 0.9889 - val_acc: 0.8400\n",
      "Epoch 951/1000\n",
      "10000/10000 [==============================] - 5s 503us/step - loss: 0.0382 - acc: 0.9898 - val_loss: 1.1316 - val_acc: 0.8450\n",
      "Epoch 952/1000\n",
      "10000/10000 [==============================] - 5s 510us/step - loss: 0.0528 - acc: 0.9866 - val_loss: 0.9463 - val_acc: 0.8460\n",
      "Epoch 953/1000\n",
      "10000/10000 [==============================] - 5s 524us/step - loss: 0.0535 - acc: 0.9873 - val_loss: 1.0383 - val_acc: 0.8390\n",
      "Epoch 954/1000\n",
      "10000/10000 [==============================] - 5s 503us/step - loss: 0.0424 - acc: 0.9901 - val_loss: 1.1034 - val_acc: 0.8420\n",
      "Epoch 955/1000\n",
      "10000/10000 [==============================] - 5s 508us/step - loss: 0.0473 - acc: 0.9893 - val_loss: 1.0590 - val_acc: 0.8340\n",
      "Epoch 956/1000\n",
      "10000/10000 [==============================] - 5s 525us/step - loss: 0.0460 - acc: 0.9890 - val_loss: 0.9751 - val_acc: 0.8450\n",
      "Epoch 957/1000\n",
      "10000/10000 [==============================] - 5s 518us/step - loss: 0.0419 - acc: 0.9895 - val_loss: 1.1024 - val_acc: 0.8420\n",
      "Epoch 958/1000\n",
      "10000/10000 [==============================] - 5s 505us/step - loss: 0.0458 - acc: 0.9878 - val_loss: 1.1454 - val_acc: 0.8360\n",
      "Epoch 959/1000\n",
      "10000/10000 [==============================] - 5s 505us/step - loss: 0.0409 - acc: 0.9893 - val_loss: 1.1065 - val_acc: 0.8450\n",
      "Epoch 960/1000\n",
      "10000/10000 [==============================] - 5s 520us/step - loss: 0.0396 - acc: 0.9901 - val_loss: 1.0729 - val_acc: 0.8370\n",
      "Epoch 961/1000\n",
      "10000/10000 [==============================] - 5s 522us/step - loss: 0.0381 - acc: 0.9907 - val_loss: 1.0731 - val_acc: 0.8470\n",
      "Epoch 962/1000\n",
      "10000/10000 [==============================] - 5s 498us/step - loss: 0.0483 - acc: 0.9873 - val_loss: 0.9803 - val_acc: 0.8440\n",
      "Epoch 963/1000\n",
      "10000/10000 [==============================] - 5s 502us/step - loss: 0.0451 - acc: 0.9884 - val_loss: 1.0269 - val_acc: 0.8320\n",
      "Epoch 964/1000\n",
      "10000/10000 [==============================] - 6s 550us/step - loss: 0.0462 - acc: 0.9886 - val_loss: 1.0572 - val_acc: 0.8430\n",
      "Epoch 965/1000\n",
      "10000/10000 [==============================] - 6s 554us/step - loss: 0.0388 - acc: 0.9902 - val_loss: 1.1107 - val_acc: 0.8450\n",
      "Epoch 966/1000\n",
      "10000/10000 [==============================] - 5s 535us/step - loss: 0.0449 - acc: 0.9902 - val_loss: 0.9602 - val_acc: 0.8410\n",
      "Epoch 967/1000\n",
      "10000/10000 [==============================] - 5s 517us/step - loss: 0.0431 - acc: 0.9879 - val_loss: 1.0156 - val_acc: 0.8380\n",
      "Epoch 968/1000\n",
      "10000/10000 [==============================] - 5s 534us/step - loss: 0.0461 - acc: 0.9872 - val_loss: 1.0668 - val_acc: 0.8360\n",
      "Epoch 969/1000\n",
      "10000/10000 [==============================] - 5s 483us/step - loss: 0.0428 - acc: 0.9896 - val_loss: 1.0507 - val_acc: 0.8460\n",
      "Epoch 970/1000\n",
      "10000/10000 [==============================] - 5s 517us/step - loss: 0.0393 - acc: 0.9890 - val_loss: 1.1099 - val_acc: 0.8370\n",
      "Epoch 971/1000\n",
      "10000/10000 [==============================] - 5s 507us/step - loss: 0.0504 - acc: 0.9892 - val_loss: 1.1858 - val_acc: 0.8330\n",
      "Epoch 972/1000\n",
      "10000/10000 [==============================] - 5s 515us/step - loss: 0.0457 - acc: 0.9901 - val_loss: 1.0832 - val_acc: 0.8440\n",
      "Epoch 973/1000\n",
      "10000/10000 [==============================] - 5s 511us/step - loss: 0.0405 - acc: 0.9895 - val_loss: 1.0841 - val_acc: 0.8360\n",
      "Epoch 974/1000\n",
      "10000/10000 [==============================] - 5s 485us/step - loss: 0.0492 - acc: 0.9897 - val_loss: 1.1323 - val_acc: 0.8420\n",
      "Epoch 975/1000\n",
      "10000/10000 [==============================] - 5s 507us/step - loss: 0.0420 - acc: 0.9891 - val_loss: 1.1834 - val_acc: 0.8370\n",
      "Epoch 976/1000\n",
      "10000/10000 [==============================] - 5s 515us/step - loss: 0.0477 - acc: 0.9882 - val_loss: 1.1383 - val_acc: 0.8320\n",
      "Epoch 977/1000\n",
      "10000/10000 [==============================] - 5s 505us/step - loss: 0.0393 - acc: 0.9887 - val_loss: 1.2603 - val_acc: 0.8340\n",
      "Epoch 978/1000\n",
      "10000/10000 [==============================] - 5s 503us/step - loss: 0.0396 - acc: 0.9905 - val_loss: 1.2405 - val_acc: 0.8290\n",
      "Epoch 979/1000\n",
      "10000/10000 [==============================] - 5s 496us/step - loss: 0.0506 - acc: 0.9885 - val_loss: 1.0917 - val_acc: 0.8420\n",
      "Epoch 980/1000\n",
      "10000/10000 [==============================] - 5s 499us/step - loss: 0.0441 - acc: 0.9882 - val_loss: 1.1651 - val_acc: 0.8410\n",
      "Epoch 981/1000\n",
      "10000/10000 [==============================] - 5s 494us/step - loss: 0.0372 - acc: 0.9900 - val_loss: 1.2617 - val_acc: 0.8410\n",
      "Epoch 982/1000\n",
      "10000/10000 [==============================] - 5s 494us/step - loss: 0.0542 - acc: 0.9861 - val_loss: 1.1361 - val_acc: 0.8380\n",
      "Epoch 983/1000\n",
      "10000/10000 [==============================] - 5s 490us/step - loss: 0.0406 - acc: 0.9897 - val_loss: 1.1029 - val_acc: 0.8450\n",
      "Epoch 984/1000\n",
      "10000/10000 [==============================] - 5s 487us/step - loss: 0.0426 - acc: 0.9905 - val_loss: 1.2641 - val_acc: 0.8310\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 985/1000\n",
      "10000/10000 [==============================] - 6s 565us/step - loss: 0.0415 - acc: 0.9908 - val_loss: 1.3362 - val_acc: 0.8320\n",
      "Epoch 986/1000\n",
      "10000/10000 [==============================] - 6s 567us/step - loss: 0.0443 - acc: 0.9911 - val_loss: 0.9673 - val_acc: 0.8500\n",
      "Epoch 987/1000\n",
      "10000/10000 [==============================] - 6s 577us/step - loss: 0.0422 - acc: 0.9893 - val_loss: 1.1418 - val_acc: 0.8360\n",
      "Epoch 988/1000\n",
      "10000/10000 [==============================] - 6s 564us/step - loss: 0.0445 - acc: 0.9888 - val_loss: 1.0538 - val_acc: 0.8380\n",
      "Epoch 989/1000\n",
      "10000/10000 [==============================] - 5s 550us/step - loss: 0.0430 - acc: 0.9900 - val_loss: 1.0872 - val_acc: 0.8400\n",
      "Epoch 990/1000\n",
      "10000/10000 [==============================] - 5s 488us/step - loss: 0.0433 - acc: 0.9889 - val_loss: 1.3102 - val_acc: 0.8340\n",
      "Epoch 991/1000\n",
      "10000/10000 [==============================] - 5s 492us/step - loss: 0.0371 - acc: 0.9909 - val_loss: 1.1503 - val_acc: 0.8390\n",
      "Epoch 992/1000\n",
      "10000/10000 [==============================] - 5s 522us/step - loss: 0.0472 - acc: 0.9897 - val_loss: 1.1337 - val_acc: 0.8370\n",
      "Epoch 993/1000\n",
      "10000/10000 [==============================] - 5s 538us/step - loss: 0.0380 - acc: 0.9894 - val_loss: 1.2615 - val_acc: 0.8470\n",
      "Epoch 994/1000\n",
      "10000/10000 [==============================] - 5s 546us/step - loss: 0.0489 - acc: 0.9888 - val_loss: 1.1629 - val_acc: 0.8410\n",
      "Epoch 995/1000\n",
      "10000/10000 [==============================] - 5s 540us/step - loss: 0.0524 - acc: 0.9881 - val_loss: 0.9729 - val_acc: 0.8430\n",
      "Epoch 996/1000\n",
      "10000/10000 [==============================] - 5s 518us/step - loss: 0.0461 - acc: 0.9885 - val_loss: 0.9960 - val_acc: 0.8480\n",
      "Epoch 997/1000\n",
      "10000/10000 [==============================] - 5s 534us/step - loss: 0.0356 - acc: 0.9901 - val_loss: 1.0769 - val_acc: 0.8410\n",
      "Epoch 998/1000\n",
      "10000/10000 [==============================] - 5s 542us/step - loss: 0.0404 - acc: 0.9900 - val_loss: 1.0542 - val_acc: 0.8450\n",
      "Epoch 999/1000\n",
      "10000/10000 [==============================] - 5s 536us/step - loss: 0.0443 - acc: 0.9892 - val_loss: 1.1568 - val_acc: 0.8460\n",
      "Epoch 1000/1000\n",
      "10000/10000 [==============================] - 5s 538us/step - loss: 0.0507 - acc: 0.9888 - val_loss: 1.0678 - val_acc: 0.8370\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([inputs_train,questions_train],answers_train, batch_size = 32, epochs = 1000, validation_data = ([inputs_test,questions_test],answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Z_chatbot_100_epochs.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Lets plot the increase of accuracy as we increase the number of training epochs\n",
    "#We can see that without any training the acc is about 50%, random guessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To load a model that we have already trained and saved:\n",
    "model.load_weights('Z_chatbot_100_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets check out the predictions on the test set:\n",
    "#These are just probabilities for every single word on the vocab\n",
    "pred_results = model.predict(([inputs_test,questions_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'got',\n",
       "  'the',\n",
       "  'milk',\n",
       "  'there',\n",
       "  '.',\n",
       "  'John',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'John', 'in', 'the', 'kitchen', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First test data point\n",
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.4758190e-21, 2.1397022e-21, 2.2722944e-21, 1.9776182e-21,\n",
       "       1.7983421e-21, 1.9400778e-21, 1.6792089e-21, 2.0177312e-21,\n",
       "       2.2013671e-21, 2.1278508e-21, 1.8952951e-21, 1.9446645e-21,\n",
       "       2.1805394e-21, 2.1526293e-21, 2.1304580e-21, 2.4526099e-21,\n",
       "       1.9765925e-21, 1.8287746e-21, 2.2381072e-21, 1.0000000e+00,\n",
       "       2.3029066e-21, 2.1592005e-21, 2.5348889e-21, 1.8851353e-21,\n",
       "       1.8703010e-21, 2.3107912e-21, 2.3018439e-21, 2.2044449e-19,\n",
       "       2.0388772e-21, 2.3365857e-21, 2.1607000e-21, 1.9910922e-21,\n",
       "       2.3918412e-21, 2.1491505e-21, 1.7650330e-21, 2.4313060e-21,\n",
       "       2.0611253e-21, 2.2488391e-21], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#These are the probabilities for the vocab words using the 1st sentence\n",
    "pred_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(pred_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "for key,val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See probability:\n",
    "pred_results[0][val_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now, we can make our own questions using the vocabulary we have\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story = 'Sandra picked up the milk . Mary travelled left . '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sandra', 'picked', 'up', 'the', 'milk', '.', 'Mary', 'travelled', 'left']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = 'Sandra got the milk ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sandra', 'got', 'the', 'milk', '?']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put the data in the same format as before\n",
    "my_data = [(my_story.split(), my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize this data\n",
    "my_story, my_ques, my_ans = vectorize_stories(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the prediction\n",
    "pred_results = model.predict(([my_story,my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(pred_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "#Correct prediction!\n",
    "for key,val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9867547"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confidence\n",
    "pred_results[0][val_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
